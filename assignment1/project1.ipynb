{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>**IBM Model 1**</h1>\n",
    "\n",
    "1. a) Implement EM training (Brown et al., 1993) for IBM model 1; <br />\n",
    "    b) Implement variational inference for Bayesian IBM model 1; <br />\n",
    "    c) All of the tasks below should be performed for both models.<br />\n",
    "2. Plot the evolution of training log likelihood (or ELBO) as a function of the iteration.\n",
    "3. Plot the evolution of alignment error rate (AER) on validation data as a function of the iteration;\n",
    "4. Experiment with two criteria for model selection (i.e. deciding on number of training iterations): \n",
    "    1) convergence in terms of training log likelihood; \n",
    "    2) best AER on validation data;\n",
    "5. For the selected models, obtain Viterbi alignments for every sentence pair in a test\n",
    "corpus and compute AER using a gold-standard provided by the assistant;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import aer\n",
    "from collections import defaultdict, Counter\n",
    "from math import log2\n",
    "import numpy as np\n",
    "from random import randint\n",
    "import progressbar\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.special import digamma, gammaln "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read training source corpus\n",
      "Read training target corpus\n",
      "Read validation corpora\n"
     ]
    }
   ],
   "source": [
    "def read_corpus(file_name, source_language):\n",
    "    \"\"\"\n",
    "    Reads the corpus and saves each sentence in a list.\n",
    "    \"\"\"\n",
    "    \n",
    "    corpus = []\n",
    "    \n",
    "    with open(file_name, \"r\", encoding='utf8') as f:\n",
    "        for line in f:\n",
    "            line = line.replace(\"\\n\", \"\")\n",
    "            sentence = line.split()\n",
    "            \n",
    "            if source_language:\n",
    "                sentence.insert(0, \"null\")\n",
    "            corpus.append(sentence)\n",
    "    return corpus[:2000]\n",
    "\n",
    "\n",
    "def reduce_corpus(corpus):\n",
    "    \"\"\"\n",
    "    Reduces the vocabulary of the corpus by replacing each word that only\n",
    "    occurs once in the vocabulary by -LOW- in the corpus.\n",
    "    \"\"\"\n",
    "    \n",
    "    flat_corpus = [word for sentence in corpus for word in sentence]\n",
    "    word_counts = Counter(flat_corpus)\n",
    "    small_corpus = []\n",
    "    \n",
    "    for sentence in corpus:\n",
    "        small_sentence = []\n",
    "        \n",
    "        for word in sentence:\n",
    "            if word_counts[word] != 1:\n",
    "                small_sentence.append(word)\n",
    "            else:\n",
    "                small_sentence.append(\"-LOW-\")\n",
    "        small_corpus.append(small_sentence)\n",
    "    return small_corpus\n",
    "\n",
    "    \n",
    "train_source = read_corpus(\"training/hansards.36.2.e\", True)\n",
    "train_source = reduce_corpus(train_source)\n",
    "print(\"Read training source corpus\")\n",
    "train_target = read_corpus(\"training/hansards.36.2.f\", False)\n",
    "train_target = reduce_corpus(train_target)\n",
    "print(\"Read training target corpus\")\n",
    "val_source = read_corpus(\"validation/dev.e\", True)\n",
    "val_target = read_corpus(\"validation/dev.f\", False)\n",
    "print(\"Read validation corpora\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7% (152 of 2000) |#                     | Elapsed Time: 0:00:00 ETA:  0:00:01"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialising parameters...\n",
      "Iteration #0 out of 9\n",
      "Doing E-step...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (2000 of 2000) |#####################| Elapsed Time: 0:00:02 Time: 0:00:02\n",
      "100% (2444 of 2444) |#####################| Elapsed Time: 0:00:00 Time: 0:00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doing M-step...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7% (152 of 2000) |#                     | Elapsed Time: 0:00:00 ETA:  0:00:01"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-48081.10720249418\n",
      "0.518597236981934\n",
      "Iteration #1 out of 9\n",
      "Doing E-step...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (2000 of 2000) |#####################| Elapsed Time: 0:00:01 Time: 0:00:01\n",
      "100% (2444 of 2444) |#####################| Elapsed Time: 0:00:00 Time: 0:00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doing M-step...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11% (228 of 2000) |##                    | Elapsed Time: 0:00:00 ETA:  0:00:01"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-29819.011814967555\n",
      "0.4720430107526882\n",
      "Iteration #2 out of 9\n",
      "Doing E-step...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (2000 of 2000) |#####################| Elapsed Time: 0:00:01 Time: 0:00:01\n",
      "100% (2444 of 2444) |#####################| Elapsed Time: 0:00:00 Time: 0:00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doing M-step...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13% (279 of 2000) |###                   | Elapsed Time: 0:00:00 ETA:  0:00:01"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-22276.970188187643\n",
      "0.47634408602150535\n",
      "Iteration #3 out of 9\n",
      "Doing E-step...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (2000 of 2000) |#####################| Elapsed Time: 0:00:01 Time: 0:00:01\n",
      "100% (2444 of 2444) |#####################| Elapsed Time: 0:00:00 Time: 0:00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doing M-step...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10% (203 of 2000) |##                    | Elapsed Time: 0:00:00 ETA:  0:00:01"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-18854.614461847737\n",
      "0.48064516129032253\n",
      "Iteration #4 out of 9\n",
      "Doing E-step...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (2000 of 2000) |#####################| Elapsed Time: 0:00:01 Time: 0:00:01\n",
      "100% (2444 of 2444) |#####################| Elapsed Time: 0:00:00 Time: 0:00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doing M-step...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8% (178 of 2000) |#                     | Elapsed Time: 0:00:00 ETA:  0:00:01"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-17127.542810965362\n",
      "0.43795620437956206\n",
      "Iteration #5 out of 9\n",
      "Doing E-step...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (2000 of 2000) |#####################| Elapsed Time: 0:00:02 Time: 0:00:02\n",
      "100% (2444 of 2444) |#####################| Elapsed Time: 0:00:00 Time: 0:00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doing M-step...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7% (152 of 2000) |#                     | Elapsed Time: 0:00:00 ETA:  0:00:01"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-16148.955744870631\n",
      "0.43169968717413976\n",
      "Iteration #6 out of 9\n",
      "Doing E-step...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (2000 of 2000) |#####################| Elapsed Time: 0:00:01 Time: 0:00:01\n",
      "100% (2444 of 2444) |#####################| Elapsed Time: 0:00:00 Time: 0:00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doing M-step...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11% (228 of 2000) |##                    | Elapsed Time: 0:00:00 ETA:  0:00:00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-15542.8407332105\n",
      "0.4369134515119917\n",
      "Iteration #7 out of 9\n",
      "Doing E-step...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (2000 of 2000) |#####################| Elapsed Time: 0:00:01 Time: 0:00:01\n",
      "100% (2444 of 2444) |#####################| Elapsed Time: 0:00:00 Time: 0:00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doing M-step...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8% (178 of 2000) |#                     | Elapsed Time: 0:00:00 ETA:  0:00:01"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-15142.57322907176\n",
      "0.44525547445255476\n",
      "Iteration #8 out of 9\n",
      "Doing E-step...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (2000 of 2000) |#####################| Elapsed Time: 0:00:01 Time: 0:00:01\n",
      "100% (2444 of 2444) |#####################| Elapsed Time: 0:00:00 Time: 0:00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doing M-step...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8% (178 of 2000) |#                     | Elapsed Time: 0:00:00 ETA:  0:00:01"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-14865.677348182091\n",
      "0.45151199165797706\n",
      "Iteration #9 out of 9\n",
      "Doing E-step...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (2000 of 2000) |#####################| Elapsed Time: 0:00:01 Time: 0:00:01\n",
      "100% (2444 of 2444) |#####################| Elapsed Time: 0:00:00 Time: 0:00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doing M-step...\n",
      "-14667.239343214545\n",
      "0.45359749739311783\n"
     ]
    }
   ],
   "source": [
    "def initialise_parameters(source_corpus, target_corpus):\n",
    "    \"\"\"\n",
    "    Initialises the conditional probability of generating a source \n",
    "    word from a target word for all possible pairs of words in the source \n",
    "    and target sentences to 5 and then normalises the parameters such that \n",
    "    the initialisation is uniform.\n",
    "    \"\"\"\n",
    "    \n",
    "    flat_corpus = [word for sentence in source_corpus for word in sentence]\n",
    "    amount_source_words = len(set(flat_corpus))\n",
    "    theta0 = 1/amount_source_words\n",
    "    return defaultdict(lambda: defaultdict(lambda: theta0))\n",
    "\n",
    "\n",
    "def expectation_maximisation(train_source, train_target, val_source,\n",
    "                             val_target, parameters, num_iterations, \n",
    "                             min_perplexity_change):\n",
    "    \"\"\"\n",
    "    Do the EM algorithm until perplexity decreases very little or until \n",
    "    the number of iterations is reached.\n",
    "    \"\"\"\n",
    "    \n",
    "    old_perplexity = -100000\n",
    "    perplexities = []\n",
    "    aers = []\n",
    "    \n",
    "    for k in range(0, num_iterations):\n",
    "        print(\"Iteration #\" + str(k), \"out of\", num_iterations - 1)\n",
    "        counts_single = defaultdict(lambda: 1.0)\n",
    "        counts_pairs = defaultdict(lambda: defaultdict(float))\n",
    "        counts_single, counts_pairs = e_step(train_source, train_target,\n",
    "                                             parameters, counts_single, \n",
    "                                             counts_pairs)\n",
    "        parameters = m_step(parameters, counts_single, counts_pairs)\n",
    "        perplexity = compute_perplexity(parameters, train_source, train_target)\n",
    "        alignments = get_best_alignment(val_source, val_target, parameters)\n",
    "        aers.append(compute_aer(alignments))\n",
    "        perplexities.append(perplexity)\n",
    "        \n",
    "        if abs(perplexity - old_perplexity) < min_perplexity_change:\n",
    "            return perplexities, aers\n",
    "        else:\n",
    "            old_perplexity = perplexity\n",
    "    return perplexities, aers\n",
    "    \n",
    "    \n",
    "def e_step(source_corpus, target_corpus, parameters, counts_single, \n",
    "           counts_pairs):\n",
    "    \"\"\"\n",
    "    Do the E-step by computing the expected counts.\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"Doing E-step...\")\n",
    "    \n",
    "    with progressbar.ProgressBar(max_value=len(target_corpus)) as bar:\n",
    "        for n in range(len(target_corpus)):\n",
    "            target_sentence = target_corpus[n]\n",
    "            source_sentence = source_corpus[n]\n",
    "\n",
    "            for i in range(len(target_sentence)):\n",
    "                normalisation_term = 0\n",
    "                target_word = target_sentence[i]\n",
    "\n",
    "                for j in range(len(source_sentence)):\n",
    "                    source_word = source_sentence[j]\n",
    "                    normalisation_term += parameters[source_word][target_word]\n",
    "                for j in range(len(source_sentence)):\n",
    "                    source_word = source_sentence[j]\n",
    "                    expected_count = parameters[source_word][target_word]/normalisation_term\n",
    "                    counts_pairs[source_word][target_word] += expected_count\n",
    "                    counts_single[source_word] += expected_count\n",
    "            bar.update(n)\n",
    "    return counts_single, counts_pairs\n",
    "\n",
    "\n",
    "def m_step(parameters, counts_single, counts_pairs):\n",
    "    \"\"\"\n",
    "    Do the M-step by normalising the parameters.\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"Doing M-step...\")\n",
    "    \n",
    "    with progressbar.ProgressBar(max_value=len(counts_pairs)) as bar:\n",
    "        i = 0\n",
    "        for source_word, target_words in counts_pairs.items():\n",
    "            for target_word, expected_count in target_words.items():\n",
    "                parameters[source_word][target_word] = expected_count/counts_single[source_word]\n",
    "            i += 1\n",
    "            bar.update(i)\n",
    "    return parameters\n",
    "\n",
    "\n",
    "def compute_perplexity(theta_dict, source_corpus, target_corpus):\n",
    "    \"\"\"\n",
    "    Computes the perplexity of the corpus.\n",
    "    \"\"\"\n",
    "    \n",
    "    logprobs = []\n",
    "    total_sum = 0\n",
    "    \n",
    "    for n in range(len(source_corpus)):\n",
    "        english_sentence = source_corpus[n]\n",
    "        french_sentence = target_corpus[n]\n",
    "        french_sum = 0\n",
    "        for j in range(len(french_sentence)): \n",
    "            f_j = french_sentence[j]\n",
    "            log_sum = []\n",
    "            for i in range(len(english_sentence)): \n",
    "                e_i = english_sentence[i]\n",
    "                log_sum.append(theta_dict[e_i][f_j])\n",
    "            french_sum += np.log(np.sum(log_sum))\n",
    "        total_sum += french_sum\n",
    "    perplexity = total_sum\n",
    "    print(perplexity)\n",
    "    return perplexity\n",
    "\n",
    "\n",
    "def calculate_likelihood(source_corpus, target_corpus, parameters):\n",
    "    \"\"\"\n",
    "    Calculates the likelihood over te corpus:\n",
    "    sum_<f,e> sum^m_i=1 log sum^l_j=0 pi_t(target|source) \n",
    "    \"\"\"\n",
    "    \n",
    "    corpus_likelihood = 0\n",
    "    \n",
    "    for n in range(len(source_corpus)):\n",
    "        source_sentence = source_corpus[n]\n",
    "        target_sentence = target_corpus[n]\n",
    "        target_likelihood = 0\n",
    "        \n",
    "        for i in range(len(target_sentence)):\n",
    "            target_word = target_sentence[i]\n",
    "            source_likelihood = 0\n",
    "            \n",
    "            for j in range(len(source_sentence)):\n",
    "                source_word = source_sentence[j]\n",
    "                source_likelihood += parameters[source_word][target_word]\n",
    "            target_likelihood += log2(source_likelihood)\n",
    "        corpus_likelihood += target_likelihood\n",
    "    return corpus_likelihood\n",
    "   \n",
    "    \n",
    "def get_best_alignment(source_corpus, target_corpus, parameters):\n",
    "    \"\"\"\n",
    "    Gets the best alignment for each sentence and saves the alignment\n",
    "    in a list of lists that holds tuples for each position in the sentence\n",
    "    and looks as follows:\n",
    "    (sentence_index, target_word_index, source_word_index).\n",
    "    \"\"\"\n",
    "    \n",
    "    alignments = []\n",
    "    \n",
    "    for n in range(len(source_corpus)):\n",
    "        source_sentence = source_corpus[n]\n",
    "        target_sentence = target_corpus[n]\n",
    "        alignment = []\n",
    "        \n",
    "        for i in range(len(target_sentence)):\n",
    "            target_word = target_sentence[i]\n",
    "            best_prob = 0\n",
    "            best_j = 0\n",
    "            \n",
    "            for j in range(len(source_sentence)):\n",
    "                source_word = source_sentence[j]\n",
    "                prob = parameters[source_word][target_word]\n",
    "                \n",
    "                if prob > best_prob:\n",
    "                    best_prob = prob\n",
    "                    best_j = j\n",
    "                    \n",
    "            if best_j != 0:    \n",
    "                alignment.append((n, best_j, i+1))\n",
    "        alignments.append(alignment)\n",
    "    return alignments\n",
    "\n",
    "\n",
    "def compute_aer(predictions):\n",
    "    \"\"\"\n",
    "    Computes the Alignment Error Rate.\n",
    "    \"\"\"\n",
    "    \n",
    "    gold_sets = aer.read_naacl_alignments(\"validation/dev.wa.nonullalign\")\n",
    "    metric = aer.AERSufficientStatistics()\n",
    "    \n",
    "    for gold, prediction in zip(gold_sets, predictions):\n",
    "        prediction = set([(alignment[1], alignment[2]) for alignment in prediction])\n",
    "        metric.update(sure=gold[0], probable=gold[1], predicted=prediction)\n",
    "    print(metric.aer())\n",
    "    return metric.aer()\n",
    "    \n",
    "print(\"Initialising parameters...\")\n",
    "initial_params = initialise_parameters(train_source, train_target)\n",
    "perplexities, aers = expectation_maximisation(train_source, train_target, \n",
    "                                              val_source, val_target,\n",
    "                                              initial_params, 10, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZ0AAAEWCAYAAAC9qEq5AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f487a4a67f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.arange(1, len(perplexities)+1), perplexities)\n",
    "plt.title(\"Evolution of perplexity\")\n",
    "plt.xlabel(\"Iterations\")\n",
    "plt.ylabel(\"Perplexity\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>IBM Model 2</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration #0 out of 9\n",
      "-43825.6879894\n",
      "Iteration #1 out of 9\n",
      "-27689.9665298\n",
      "Iteration #2 out of 9\n",
      "-17920.2666\n",
      "Iteration #3 out of 9\n",
      "-14109.4795137\n",
      "Iteration #4 out of 9\n",
      "-13396.0014646\n",
      "Iteration #5 out of 9\n",
      "-13721.8589776\n",
      "Iteration #6 out of 9\n",
      "-14185.103931\n",
      "Iteration #7 out of 9\n",
      "-14544.6924467\n",
      "Iteration #8 out of 9\n",
      "-14789.8907897\n",
      "Iteration #9 out of 9\n",
      "-14957.5577081\n",
      "0.4627329192546584\n"
     ]
    }
   ],
   "source": [
    "iterations = 10\n",
    "sub = 1\n",
    "\n",
    "\n",
    "def expectation_maximisation2(source_corpus, target_corpus, parameters, num_iterations, min_perplexity_change):\n",
    "    q = defaultdict(lambda: defaultdict(lambda: defaultdict(lambda: defaultdict(lambda: 0.1))))\n",
    "    old_perplexity = -100000\n",
    "    \n",
    "    for k in range(0, num_iterations):\n",
    "        print(\"Iteration #\" + str(k), \"out of\", num_iterations - 1)\n",
    "        \n",
    "        counts_pairs = defaultdict(lambda: defaultdict(lambda: 0.))\n",
    "        counts_alignments = defaultdict(lambda: defaultdict(lambda: defaultdict(lambda: defaultdict(lambda: 0.))))\n",
    "        counts_single = defaultdict(lambda: 0.)\n",
    "        counts_pairs, counts_single, counts_alignments = e_step2(source_corpus, target_corpus, counts_pairs, counts_single, counts_alignments, q)\n",
    "        parameters, q = m_step2(parameters, q, counts_alignments, counts_pairs, counts_single)\n",
    "        perplexity = compute_perplexity(parameters, source_corpus, target_corpus)\n",
    "        print(perplexity)\n",
    "        \n",
    "        if abs(perplexity - old_perplexity) < min_perplexity_change:\n",
    "            return parameters\n",
    "        else:\n",
    "            old_perplexity = perplexity\n",
    "    return parameters        \n",
    "\n",
    "\n",
    "def e_step2(source_corpus, target_corpus, counts_pairs, counts_single, counts_alignments, q):\n",
    "    for n in range(len(source_corpus)):\n",
    "        source_sentence = source_corpus[n]\n",
    "        target_sentence = target_corpus[n]\n",
    "        l = len(source_sentence)\n",
    "        m = len(target_sentence)\n",
    "\n",
    "        for i, target_word in enumerate(target_sentence):\n",
    "            delta_denominator = sum([q[j_k][i][l][m]*parameters[source_sentence[j_k]][target_word] for j_k in range(l)])\n",
    "\n",
    "            for j, source_word in enumerate(source_sentence):\n",
    "                delta = (q[j][i][l][m]*parameters[source_word][target_word]) / delta_denominator\n",
    "\n",
    "                counts_pairs[source_word][target_word] += delta\n",
    "                counts_single[source_word] += delta\n",
    "                counts_alignments[l][m][i][j] += delta\n",
    "    return counts_pairs, counts_single, counts_alignments\n",
    "\n",
    "\n",
    "def m_step2(parameters, q, counts_alignments, counts_pairs, counts_single):\n",
    "    for j in q.keys():\n",
    "        for i in q[j].keys():\n",
    "            for l in q[j][i].keys():\n",
    "                for m in q[j][i][l].keys():\n",
    "                    q[j][i][l][m] = counts_alignments[l][m][i][j] / sum(counts_alignments[l][m][i].values())\n",
    "    \n",
    "    for source_word, target_words in parameters.items():\n",
    "        for target_word in target_words:\n",
    "            parameters[source_word][target_word] = counts_pairs[source_word][target_word]/counts_single[source_word]\n",
    "    return parameters, q\n",
    "\n",
    "\n",
    "parameters = initialise_parameters(train_source_corpus, train_target_corpus)\n",
    "parameters = expectation_maximisation2(train_source_corpus, train_target_corpus, parameters, \n",
    "                                       10, 5)\n",
    "alignments = get_best_alignment(val_source_corpus, val_target_corpus, parameters)\n",
    "compute_aer(alignments)\n",
    "\n",
    "# q = defaultdict(lambda: defaultdict(lambda: defaultdict(lambda: defaultdict(lambda: 0.1))))\n",
    "# perps = []\n",
    "\n",
    "# for s in range(iterations):\n",
    "    \n",
    "#     print('iteration', s)\n",
    "#     # initialize all counts to 0\n",
    "    \n",
    "#     counts_pairs = defaultdict(lambda: defaultdict(lambda: 0.))\n",
    "#     counts_alignments = defaultdict(lambda: defaultdict(lambda: defaultdict(lambda: defaultdict(lambda: 0.))))\n",
    "#     counts_single = defaultdict(lambda: 0.)\n",
    "    \n",
    "#     for n in range(len(train_source_corpus)):\n",
    "#         source_sentence = train_source_corpus[n]\n",
    "#         target_sentence = train_target_corpus[n]\n",
    "#         l = len(source_sentence)\n",
    "#         m = len(target_sentence)\n",
    "\n",
    "#         for i, target_word in enumerate(target_sentence):\n",
    "#             delta_denominator = sum([q[j_k][i][l][m]*parameters[source_sentence[j_k]][target_word] for j_k in range(l)])\n",
    "            \n",
    "#             for j, source_word in enumerate(source_sentence):\n",
    "#                 delta = (q[j][i][l][m]*parameters[source_word][target_word]) / delta_denominator\n",
    "                \n",
    "#                 counts_pairs[source_word][target_word] += delta\n",
    "#                 counts_single[source_word] += delta\n",
    "#                 counts_alignments[l][m][i][j] += delta\n",
    "                \n",
    "#     for j in q.keys():\n",
    "#         for i in q[j].keys():\n",
    "#             for l in q[j][i].keys():\n",
    "#                 for m in q[j][i][l].keys():\n",
    "#                     q[j][i][l][m] = counts_alignments[l][m][i][j] / sum(counts_alignments[l][m][i].values())\n",
    "    \n",
    "#     for source_word, target_words in parameters.items():\n",
    "#         for target_word in target_words:\n",
    "#             parameters[source_word][target_word] = counts_pairs[source_word][target_word]/counts_single[source_word]\n",
    "                \n",
    "#     perp = compute_perplexity(parameters, train_source_corpus, train_target_corpus)\n",
    "#     perps.append(perp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZUAAAD8CAYAAAC/1zkdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nskahIiIiWaNQERGRrPn/wKVrk5G+BWoAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f98d7404208>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(perps)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variational Bayes IBM1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 th iteration out of  9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Urja\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:138: RuntimeWarning: divide by zero encountered in log\n"
     ]
    }
   ],
   "source": [
    "def elbo(theta_dict, lambda_dict, train_source_corpus, traing_target_corpus, alpha):\n",
    "\n",
    "    elbo_first_term = compute_perplexity(theta_dict, train_source_corpus, train_target_corpus)\n",
    "    elbo_second_term = 0\n",
    "\n",
    "    for english_word in english_vocab: \n",
    "        normalization = sum([lambda_dict[english_word][french_word] for french_word in french_vocab])\n",
    "        digamma_normalization = digamma(normalization)\n",
    "        gammaln_normalization = gammaln(normalization)\n",
    "        for french_word in french_vocab: \n",
    "            first_term = digamma(lambda_dict[english_word][french_word]) - digamma_normalization \n",
    "            first_term = first_term * (alpha - lambda_dict[english_word][french_word])\n",
    "            second_term = gammaln(lambda_dict[english_word][french_word]) \n",
    "            third_term = gammaln(alpha)\n",
    "            fourth_term = gammaln(len(french_vocab) * alpha)\n",
    "            elbo_second_term += first_term + second_term - third_term + fourth_term - gammaln_normalization\n",
    "\n",
    "    return elbo_first_term + elbo_second_term\n",
    "\n",
    "\n",
    "alpha = 1\n",
    "iterations = 10 \n",
    "\n",
    "theta_dict = initialise_parameters(train_source_corpus, train_target_corpus)\n",
    "lambda_dict = initialise_parameters(train_source_corpus, train_target_corpus)\n",
    "\n",
    "english_vocab = set([word for sentence in train_source_corpus for word in sentence])\n",
    "french_vocab = set([word for sentence in train_target_corpus for word in sentence])\n",
    "\n",
    "for i in range(iterations): \n",
    "    print(i, 'th iteration out of ', iterations-1)\n",
    "    counts_single = defaultdict(lambda: 1.0)\n",
    "    counts_pairs = defaultdict(lambda: defaultdict(float))\n",
    "    \n",
    "    # e step\n",
    "    for n in range(len(train_source_corpus)):\n",
    "        source_sentence = train_source_corpus[n]\n",
    "        target_sentence = train_target_corpus[n]\n",
    "        \n",
    "        for source_word in source_sentence: \n",
    "            normalization = sum([lambda_dict[source_word][target_word] for target_word in target_sentence])\n",
    "            for target_word in target_sentence: \n",
    "                theta_dict[source_word][target_word] = np.exp(digamma(lambda_dict[source_word][target_word]) - \\\n",
    "                                                              digamma(normalization))\n",
    "    # m step    \n",
    "    for source_word in english_vocab: \n",
    "        target_words = lambda_dict[source_word].keys()\n",
    "        for target_word in target_words:\n",
    "            lambda_dict[source_word][target_word] = alpha + theta_dict[source_word][target_word]\n",
    "    \n",
    "    elbo_iter = elbo(theta_dict, lambda_dict, train_source_corpus, train_target_corpus, alpha)\n",
    "    print(elbo_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sénateurs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.46825060387463785"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import operator \n",
    "\n",
    "print(max(lambda_dict['the'].items(), key=operator.itemgetter(1))[0])\n",
    "lambda_dict['the']['sénateurs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-19030.957387138806"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_perplexity(theta_dict, train_source_corpus, train_target_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
