{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>**IBM Model 1**</h1>\n",
    "\n",
    "1. a) Implement EM training (Brown et al., 1993) for IBM model 1; <br />\n",
    "    b) Implement variational inference for Bayesian IBM model 1; <br />\n",
    "    c) All of the tasks below should be performed for both models.<br />\n",
    "2. Plot the evolution of training log likelihood (or ELBO) as a function of the iteration.\n",
    "3. Plot the evolution of alignment error rate (AER) on validation data as a function of the iteration;\n",
    "4. Experiment with two criteria for model selection (i.e. deciding on number of training iterations): \n",
    "    1) convergence in terms of training log likelihood; \n",
    "    2) best AER on validation data;\n",
    "5. For the selected models, obtain Viterbi alignments for every sentence pair in a test\n",
    "corpus and compute AER using a gold-standard provided by the assistant;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import aer\n",
    "from collections import defaultdict, Counter\n",
    "from math import log2\n",
    "import numpy as np\n",
    "from random import randint\n",
    "import progressbar\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read training source corpus\n",
      "Read training target corpus\n",
      "Read validation corpora\n"
     ]
    }
   ],
   "source": [
    "def read_corpus(file_name, source_language):\n",
    "    \"\"\"\n",
    "    Reads the corpus and saves each sentence in a list.\n",
    "    \"\"\"\n",
    "    \n",
    "    corpus = []\n",
    "    \n",
    "    with open(file_name, \"r\", encoding='utf8') as f:\n",
    "        for line in f:\n",
    "            line = line.replace(\"\\n\", \"\")\n",
    "            sentence = line.split()\n",
    "            \n",
    "            if source_language:\n",
    "                sentence.insert(0, \"null\")\n",
    "            corpus.append(sentence)\n",
    "    return corpus[:5000]\n",
    "\n",
    "\n",
    "def reduce_corpus(corpus):\n",
    "    \"\"\"\n",
    "    Reduces the corpus such that words that only occur once are replaced\n",
    "    by -LOW-.\n",
    "    \"\"\"\n",
    "    \n",
    "    flat_corpus = [word for sentence in corpus for word in sentence]\n",
    "    word_counts = Counter(flat_corpus)\n",
    "    small_corpus = []\n",
    "    \n",
    "    for sentence in corpus:\n",
    "        small_sentence = []\n",
    "        \n",
    "        for word in sentence:\n",
    "            if word_counts[word] != 1:\n",
    "                small_sentence.append(word)\n",
    "            else:\n",
    "                small_sentence.append(\"-LOW-\")\n",
    "        small_corpus.append(small_sentence)\n",
    "    return small_corpus\n",
    "\n",
    "\n",
    "train_source_corpus = read_corpus(\"training/hansards.36.2.e\", True)\n",
    "train_source_corpus = reduce_corpus(train_source_corpus)\n",
    "print(\"Read training source corpus\")\n",
    "\n",
    "train_target_corpus = read_corpus(\"training/hansards.36.2.f\", False)\n",
    "train_target_corpus = reduce_corpus(train_target_corpus)\n",
    "print(\"Read training target corpus\")\n",
    "\n",
    "val_target_corpus = read_corpus(\"validation/dev.f\", False)\n",
    "val_source_corpus = read_corpus(\"validation/dev.e\", True)\n",
    "print(\"Read validation corpora\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3% (190 of 5000) |                      | Elapsed Time: 0:00:00 ETA:  0:00:03"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialising parameters...\n",
      "Iteration #0 out of 19\n",
      "Doing E-step...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (5000 of 5000) |#####################| Elapsed Time: 0:00:03 Time: 0:00:03\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doing M-step...\n",
      "Computing perplexity and AER...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3% (190 of 5000) |                      | Elapsed Time: 0:00:00 ETA:  0:00:03"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-155467.88814758134\n",
      "0.4916839916839917\n",
      "Iteration #1 out of 19\n",
      "Doing E-step...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (5000 of 5000) |#####################| Elapsed Time: 0:00:03 Time: 0:00:03\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doing M-step...\n",
      "Computing perplexity and AER...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3% (185 of 5000) |                      | Elapsed Time: 0:00:00 ETA:  0:00:02"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-100444.68769480342\n",
      "0.43664921465968587\n",
      "Iteration #2 out of 19\n",
      "Doing E-step...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (5000 of 5000) |#####################| Elapsed Time: 0:00:03 Time: 0:00:03\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doing M-step...\n",
      "Computing perplexity and AER...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3% (190 of 5000) |                      | Elapsed Time: 0:00:00 ETA:  0:00:00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-78012.46636739746\n",
      "0.44397905759162304\n",
      "Iteration #3 out of 19\n",
      "Doing E-step...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (5000 of 5000) |#####################| Elapsed Time: 0:00:03 Time: 0:00:03\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doing M-step...\n",
      "Computing perplexity and AER...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3% (190 of 5000) |                      | Elapsed Time: 0:00:00 ETA:  0:00:00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-68811.3486987745\n",
      "0.4513089005235602\n",
      "Iteration #4 out of 19\n",
      "Doing E-step...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (5000 of 5000) |#####################| Elapsed Time: 0:00:03 Time: 0:00:03\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doing M-step...\n",
      "Computing perplexity and AER...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3% (190 of 5000) |                      | Elapsed Time: 0:00:00 ETA:  0:00:00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-64464.938751727736\n",
      "0.4544502617801047\n",
      "Iteration #5 out of 19\n",
      "Doing E-step...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (5000 of 5000) |#####################| Elapsed Time: 0:00:03 Time: 0:00:03\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doing M-step...\n",
      "Computing perplexity and AER...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5% (254 of 5000) |#                     | Elapsed Time: 0:00:00 ETA:  0:00:02"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-62088.381782451834\n",
      "0.45750262329485836\n",
      "Iteration #6 out of 19\n",
      "Doing E-step...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (5000 of 5000) |#####################| Elapsed Time: 0:00:03 Time: 0:00:03\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doing M-step...\n",
      "Computing perplexity and AER...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3% (190 of 5000) |                      | Elapsed Time: 0:00:00 ETA:  0:00:00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-60643.30757849578\n",
      "0.41218274111675124\n",
      "Iteration #7 out of 19\n",
      "Doing E-step...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (5000 of 5000) |#####################| Elapsed Time: 0:00:03 Time: 0:00:03\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doing M-step...\n",
      "Computing perplexity and AER...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3% (190 of 5000) |                      | Elapsed Time: 0:00:00 ETA:  0:00:00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-59697.04386009395\n",
      "0.41218274111675124\n",
      "Iteration #8 out of 19\n",
      "Doing E-step...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (5000 of 5000) |#####################| Elapsed Time: 0:00:03 Time: 0:00:03\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doing M-step...\n",
      "Computing perplexity and AER...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3% (190 of 5000) |                      | Elapsed Time: 0:00:00 ETA:  0:00:00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-59043.60215483976\n",
      "0.41624365482233505\n",
      "Iteration #9 out of 19\n",
      "Doing E-step...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (5000 of 5000) |#####################| Elapsed Time: 0:00:03 Time: 0:00:03\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doing M-step...\n",
      "Computing perplexity and AER...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3% (190 of 5000) |                      | Elapsed Time: 0:00:00 ETA:  0:00:02"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-58574.12695408138\n",
      "0.41725888324873095\n",
      "Iteration #10 out of 19\n",
      "Doing E-step...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (5000 of 5000) |#####################| Elapsed Time: 0:00:03 Time: 0:00:03\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doing M-step...\n",
      "Computing perplexity and AER...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3% (190 of 5000) |                      | Elapsed Time: 0:00:00 ETA:  0:00:00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-58225.74338206119\n",
      "0.4164133738601824\n",
      "Iteration #11 out of 19\n",
      "Doing E-step...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (5000 of 5000) |#####################| Elapsed Time: 0:00:03 Time: 0:00:03\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doing M-step...\n",
      "Computing perplexity and AER...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3% (190 of 5000) |                      | Elapsed Time: 0:00:00 ETA:  0:00:00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-57959.833885916705\n",
      "0.4168356997971603\n",
      "Iteration #12 out of 19\n",
      "Doing E-step...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (5000 of 5000) |#####################| Elapsed Time: 0:00:03 Time: 0:00:03\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doing M-step...\n",
      "Computing perplexity and AER...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5% (254 of 5000) |#                     | Elapsed Time: 0:00:00 ETA:  0:00:02"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-57752.01775346732\n",
      "0.4168356997971603\n",
      "Iteration #13 out of 19\n",
      "Doing E-step...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (5000 of 5000) |#####################| Elapsed Time: 0:00:03 Time: 0:00:03\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doing M-step...\n",
      "Computing perplexity and AER...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5% (254 of 5000) |#                     | Elapsed Time: 0:00:00 ETA:  0:00:02"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-57586.49807312245\n",
      "0.4168356997971603\n",
      "Iteration #14 out of 19\n",
      "Doing E-step...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (5000 of 5000) |#####################| Elapsed Time: 0:00:03 Time: 0:00:03\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doing M-step...\n",
      "Computing perplexity and AER...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5% (254 of 5000) |#                     | Elapsed Time: 0:00:00 ETA:  0:00:02"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-57452.6810156507\n",
      "0.41987829614604466\n",
      "Iteration #15 out of 19\n",
      "Doing E-step...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (5000 of 5000) |#####################| Elapsed Time: 0:00:03 Time: 0:00:03\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doing M-step...\n",
      "Computing perplexity and AER...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3% (190 of 5000) |                      | Elapsed Time: 0:00:00 ETA:  0:00:03"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-57343.17549134532\n",
      "0.42233502538071066\n",
      "Iteration #16 out of 19\n",
      "Doing E-step...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (5000 of 5000) |#####################| Elapsed Time: 0:00:03 Time: 0:00:03\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doing M-step...\n",
      "Computing perplexity and AER...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3% (190 of 5000) |                      | Elapsed Time: 0:00:00 ETA:  0:00:02"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-57252.59690109533\n",
      "0.42335025380710656\n",
      "Iteration #17 out of 19\n",
      "Doing E-step...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (5000 of 5000) |#####################| Elapsed Time: 0:00:03 Time: 0:00:03\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doing M-step...\n",
      "Computing perplexity and AER...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5% (254 of 5000) |#                     | Elapsed Time: 0:00:00 ETA:  0:00:02"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-57176.94737131792\n",
      "0.42421159715157686\n",
      "Iteration #18 out of 19\n",
      "Doing E-step...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (5000 of 5000) |#####################| Elapsed Time: 0:00:03 Time: 0:00:03\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doing M-step...\n",
      "Computing perplexity and AER...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5% (254 of 5000) |#                     | Elapsed Time: 0:00:00 ETA:  0:00:02"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-57113.19155107973\n",
      "0.4252288911495422\n",
      "Iteration #19 out of 19\n",
      "Doing E-step...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (5000 of 5000) |#####################| Elapsed Time: 0:00:03 Time: 0:00:03\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doing M-step...\n",
      "Computing perplexity and AER...\n",
      "-57058.98158463248\n",
      "0.4252288911495422\n"
     ]
    }
   ],
   "source": [
    "def initialise_parameters(source_corpus, target_corpus):\n",
    "    \"\"\"\n",
    "    Initialises the conditional probability of generating a source \n",
    "    word from a target word for all possible pairs of words in the source \n",
    "    and target sentences uniformly.\n",
    "    \"\"\"\n",
    "    \n",
    "    flat_corpus = [word for sentence in source_corpus for word in sentence]\n",
    "    amount_source_words = len(set(flat_corpus))\n",
    "    theta0 = 1/amount_source_words\n",
    "    return defaultdict(lambda: defaultdict(lambda: theta0))\n",
    "\n",
    "\n",
    "def expectation_maximisation(source_corpus, target_corpus, parameters, \n",
    "                             num_iterations, min_perplexity_change,\n",
    "                             source_validation, target_validation):\n",
    "    \"\"\"\n",
    "    Do the EM algorithm until perplexity decreases very little or until \n",
    "    the number of iterations is reached.\n",
    "    \"\"\"\n",
    "    \n",
    "    old_perplexity = -100000\n",
    "    perplexities = []\n",
    "    aers = []\n",
    "    \n",
    "    for k in range(0, num_iterations):\n",
    "        print(\"Iteration #\" + str(k), \"out of\", num_iterations - 1)\n",
    "        counts_single = defaultdict(lambda: 1.0)\n",
    "        counts_pairs = defaultdict(lambda: defaultdict(float))\n",
    "        counts_single, counts_pairs = e_step(source_corpus, target_corpus,\n",
    "                                             parameters, counts_single, \n",
    "                                             counts_pairs)\n",
    "        parameters = m_step(parameters, counts_single, counts_pairs)\n",
    "        print(\"Computing perplexity and AER...\")\n",
    "        perplexity = compute_perplexity(parameters, source_corpus, target_corpus)\n",
    "        perplexities.append(perplexity)     \n",
    "        alignments = get_best_alignment(source_validation, target_validation, parameters)\n",
    "        val_aer = compute_aer(alignments)\n",
    "        aers.append(val_aer)\n",
    "        \n",
    "        if abs(perplexity - old_perplexity) < min_perplexity_change:\n",
    "            return perplexities, aers\n",
    "        else:\n",
    "            old_perplexity = perplexity\n",
    "    return perplexities, aers\n",
    "    \n",
    "    \n",
    "def e_step(source_corpus, target_corpus, parameters, counts_single, \n",
    "           counts_pairs):\n",
    "    \"\"\"\n",
    "    Do the E-step by computing the expected counts.\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"Doing E-step...\")\n",
    "    \n",
    "    with progressbar.ProgressBar(max_value=len(target_corpus)) as bar:\n",
    "        for n in range(len(target_corpus)):\n",
    "            target_sentence = target_corpus[n]\n",
    "            source_sentence = source_corpus[n]\n",
    "\n",
    "            for i in range(len(target_sentence)):\n",
    "                normalisation_term = 0\n",
    "                target_word = target_sentence[i]\n",
    "\n",
    "                for j in range(len(source_sentence)):\n",
    "                    source_word = source_sentence[j]\n",
    "                    normalisation_term += parameters[source_word][target_word]\n",
    "                for j in range(len(source_sentence)):\n",
    "                    source_word = source_sentence[j]\n",
    "                    expected_count = parameters[source_word][target_word]/normalisation_term\n",
    "                    counts_pairs[source_word][target_word] += expected_count\n",
    "                    counts_single[source_word] += expected_count\n",
    "            bar.update(n)\n",
    "    return counts_single, counts_pairs\n",
    "\n",
    "\n",
    "def m_step(parameters, counts_single, counts_pairs):\n",
    "    \"\"\"\n",
    "    Do the M-step by normalising the parameters.\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"Doing M-step...\")\n",
    "    for source_word, target_words in counts_pairs.items():\n",
    "        for target_word, expected_count in target_words.items():\n",
    "            parameters[source_word][target_word] = expected_count/counts_single[source_word]\n",
    "    return parameters\n",
    "\n",
    "\n",
    "def compute_perplexity(theta_dict, source_corpus, target_corpus):\n",
    "    \"\"\"\n",
    "    Computes the perplexity of a corpus.\n",
    "    \"\"\"\n",
    "    \n",
    "    logprobs = []\n",
    "    total_sum = 0\n",
    "    \n",
    "    for n in range(len(source_corpus)):\n",
    "        english_sentence = source_corpus[n]\n",
    "        french_sentence = target_corpus[n]\n",
    "        french_sum = 0\n",
    "        for j in range(len(french_sentence)): \n",
    "            f_j = french_sentence[j]\n",
    "            log_sum = []\n",
    "            for i in range(len(english_sentence)): \n",
    "                e_i = english_sentence[i]\n",
    "                log_sum.append(theta_dict[e_i][f_j])\n",
    "            french_sum += np.log(np.sum(log_sum))\n",
    "        total_sum += french_sum\n",
    "    perplexity = total_sum\n",
    "    print(perplexity)\n",
    "    return perplexity\n",
    "   \n",
    "    \n",
    "def get_best_alignment(source_corpus, target_corpus, parameters):\n",
    "    \"\"\"\n",
    "    Gets the best alignment for each sentence and saves the alignment\n",
    "    in a list of lists that holds tuples for each position in the sentence\n",
    "    and looks as follows:\n",
    "    (sentence_index, target_word_index, source_word_index).\n",
    "    \"\"\"\n",
    "    \n",
    "    alignments = []\n",
    "    \n",
    "    for n in range(len(source_corpus)):\n",
    "        source_sentence = source_corpus[n]\n",
    "        target_sentence = target_corpus[n]\n",
    "        alignment = []\n",
    "        \n",
    "        for i in range(len(target_sentence)):\n",
    "            target_word = target_sentence[i]\n",
    "            best_prob = 0\n",
    "            best_j = 0\n",
    "            \n",
    "            for j in range(len(source_sentence)):\n",
    "                source_word = source_sentence[j]\n",
    "                prob = parameters[source_word][target_word]\n",
    "                \n",
    "                if prob > best_prob:\n",
    "                    best_prob = prob\n",
    "                    best_j = j\n",
    "                    \n",
    "            if best_j != 0:    \n",
    "                alignment.append((n, best_j, i+1))\n",
    "        alignments.append(alignment)\n",
    "    return alignments\n",
    "\n",
    "\n",
    "def compute_aer(predictions):\n",
    "    \"\"\"\n",
    "    Computes the Alignment Error Rate.\n",
    "    \"\"\"\n",
    "    \n",
    "    gold_sets = aer.read_naacl_alignments(\"validation/dev.wa.nonullalign\")\n",
    "    metric = aer.AERSufficientStatistics()\n",
    "    \n",
    "    for gold, prediction in zip(gold_sets, predictions):\n",
    "        prediction = set([(alignment[1], alignment[2]) for alignment in prediction])\n",
    "        metric.update(sure=gold[0], probable=gold[1], predicted=prediction)\n",
    "    print(metric.aer())\n",
    "    return metric.aer()\n",
    "\n",
    "\n",
    "print(\"Initialising parameters...\")\n",
    "initial_params = initialise_parameters(train_source_corpus, train_target_corpus)\n",
    "perplexity, val_aer = expectation_maximisation(train_source_corpus, train_target_corpus,  \n",
    "                                               initial_params, 20, 50, val_source_corpus, \n",
    "                                               val_target_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib tk\n",
    "plt.plot(np.arange(1, len(val_aer)+1), val_aer)\n",
    "plt.title(\"Evolution of AER\")\n",
    "plt.xlabel(\"Iterations\")\n",
    "plt.ylabel(\"AER\")\n",
    "plt.show()\n",
    "\n",
    "# %matplotlib tk\n",
    "# plt.plot(np.arange(1, len(perplexity)+1), perplexity)\n",
    "# plt.title(\"Evolution of Perplexity\")\n",
    "# plt.xlabel(\"Iterations\")\n",
    "# plt.ylabel(\"Perplexity\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>IBM Model 2</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterations = 10\n",
    "sub = 1\n",
    "\n",
    "\n",
    "def expectation_maximisation2(source_corpus, target_corpus, parameters, num_iterations, min_perplexity_change):\n",
    "    q = defaultdict(lambda: defaultdict(lambda: defaultdict(lambda: defaultdict(lambda: 0.1))))\n",
    "    old_perplexity = -100000\n",
    "    \n",
    "    for k in range(0, num_iterations):\n",
    "        print(\"Iteration #\" + str(k), \"out of\", num_iterations - 1)\n",
    "        \n",
    "        counts_pairs = defaultdict(lambda: defaultdict(lambda: 0.))\n",
    "        counts_alignments = defaultdict(lambda: defaultdict(lambda: defaultdict(lambda: defaultdict(lambda: 0.))))\n",
    "        counts_single = defaultdict(lambda: 0.)\n",
    "        counts_pairs, counts_single, counts_alignments = e_step2(source_corpus, target_corpus, counts_pairs, counts_single, counts_alignments, q)\n",
    "        parameters, q = m_step2(parameters, q, counts_alignments, counts_pairs, counts_single)\n",
    "        perplexity = compute_perplexity(parameters, source_corpus, target_corpus)\n",
    "        print(perplexity)\n",
    "        \n",
    "        if abs(perplexity - old_perplexity) < min_perplexity_change:\n",
    "            return parameters\n",
    "        else:\n",
    "            old_perplexity = perplexity\n",
    "    return parameters        \n",
    "\n",
    "\n",
    "def e_step2(source_corpus, target_corpus, counts_pairs, counts_single, counts_alignments, q):\n",
    "    for n in range(len(source_corpus)):\n",
    "        source_sentence = source_corpus[n]\n",
    "        target_sentence = target_corpus[n]\n",
    "        l = len(source_sentence)\n",
    "        m = len(target_sentence)\n",
    "\n",
    "        for i, target_word in enumerate(target_sentence):\n",
    "            delta_denominator = sum([q[j_k][i][l][m]*parameters[source_sentence[j_k]][target_word] for j_k in range(l)])\n",
    "\n",
    "            for j, source_word in enumerate(source_sentence):\n",
    "                delta = (q[j][i][l][m]*parameters[source_word][target_word]) / delta_denominator\n",
    "\n",
    "                counts_pairs[source_word][target_word] += delta\n",
    "                counts_single[source_word] += delta\n",
    "                counts_alignments[l][m][i][j] += delta\n",
    "    return counts_pairs, counts_single, counts_alignments\n",
    "\n",
    "\n",
    "def m_step2(parameters, q, counts_alignments, counts_pairs, counts_single):\n",
    "    for j in q.keys():\n",
    "        for i in q[j].keys():\n",
    "            for l in q[j][i].keys():\n",
    "                for m in q[j][i][l].keys():\n",
    "                    q[j][i][l][m] = counts_alignments[l][m][i][j] / sum(counts_alignments[l][m][i].values())\n",
    "    \n",
    "    for source_word, target_words in parameters.items():\n",
    "        for target_word in target_words:\n",
    "            parameters[source_word][target_word] = counts_pairs[source_word][target_word]/counts_single[source_word]\n",
    "    return parameters, q\n",
    "\n",
    "\n",
    "parameters = initialise_parameters(train_source_corpus, train_target_corpus)\n",
    "parameters = expectation_maximisation2(train_source_corpus, train_target_corpus, parameters, \n",
    "                                       10, 5)\n",
    "alignments = get_best_alignment(val_source_corpus, val_target_corpus, parameters)\n",
    "compute_aer(alignments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(perps)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variational Bayes IBM1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "theta_dict =  defaultdict(lambda: defaultdict(lambda: 0.02))\n",
    "lambda_dict = defaultdict(lambda: defaultdict(lambda: 0.5))\n",
    "alpha = 0.4 \n",
    "\n",
    "for s in range(iterations):\n",
    "    \n",
    "    print('iteration', s)\n",
    "    # initialize all counts to 0\n",
    "    \n",
    "    counts_pairs = defaultdict(lambda: defaultdict(lambda: 0.))\n",
    "    counts_alignments = defaultdict(lambda: defaultdict(lambda: defaultdict(lambda: defaultdict(lambda: 0.))))\n",
    "    counts_single = defaultdict(lambda: 0.)\n",
    "    \n",
    "    for n in range(len(train_source_corpus)):\n",
    "        source_sentence = train_source_corpus[n]\n",
    "        target_sentence = train_target_corpus[n]\n",
    "\n",
    "        for i, target_word in enumerate(target_sentence):\n",
    "            \n",
    "             \n",
    "                \n",
    "    for j in q.keys():\n",
    "        for i in q[j].keys():\n",
    "            for l in q[j][i].keys():\n",
    "                for m in q[j][i][l].keys():\n",
    "                    q[j][i][l][m] = counts_alignments[l][m][i][j] / sum(counts_alignments[l][m][i].values())\n",
    "    \n",
    "    for source_word, target_words in parameters.items():\n",
    "        for target_word in target_words:\n",
    "            theta_dict[source_word][target_word] = counts_pairs[source_word][target_word]/counts_single[source_word]\n",
    "                \n",
    "    perp = compute_perplexity(parameters, train_source_corpus, train_target_corpus)\n",
    "    perps.append(perp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import digamma "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "digamma([1, 2, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
