{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>**IBM Model 1**</h1>\n",
    "\n",
    "1. a) Implement EM training (Brown et al., 1993) for IBM model 1; <br />\n",
    "    b) Implement variational inference for Bayesian IBM model 1; <br />\n",
    "    c) All of the tasks below should be performed for both models.<br />\n",
    "2. Plot the evolution of training log likelihood (or ELBO) as a function of the iteration.\n",
    "3. Plot the evolution of alignment error rate (AER) on validation data as a function of the iteration;\n",
    "4. Experiment with two criteria for model selection (i.e. deciding on number of training iterations): \n",
    "    1) convergence in terms of training log likelihood; \n",
    "    2) best AER on validation data;\n",
    "5. For the selected models, obtain Viterbi alignments for every sentence pair in a test\n",
    "corpus and compute AER using a gold-standard provided by the assistant;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import aer\n",
    "from collections import defaultdict, Counter\n",
    "from math import log2\n",
    "import numpy as np\n",
    "from random import randint\n",
    "import progressbar\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.special import digamma, gammaln "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read training source corpus\n",
      "Read training target corpus\n",
      "Read validation corpora\n"
     ]
    }
   ],
   "source": [
    "def read_corpus(file_name, source_language):\n",
    "    \"\"\"\n",
    "    Reads the corpus and saves each sentence in a list.\n",
    "    \"\"\"\n",
    "    \n",
    "    corpus = []\n",
    "    \n",
    "    with open(file_name, \"r\", encoding='utf8') as f:\n",
    "        for line in f:\n",
    "            line = line.replace(\"\\n\", \"\")\n",
    "            sentence = line.split()\n",
    "            \n",
    "            if source_language:\n",
    "                sentence.insert(0, \"null\")\n",
    "            corpus.append(sentence)\n",
    "    return corpus[:2000]\n",
    "\n",
    "\n",
    "def reduce_corpus(corpus):\n",
    "    \"\"\"\n",
    "    Reduces the vocabulary of the corpus by replacing each word that only\n",
    "    occurs once in the vocabulary by -LOW- in the corpus.\n",
    "    \"\"\"\n",
    "    \n",
    "    flat_corpus = [word for sentence in corpus for word in sentence]\n",
    "    word_counts = Counter(flat_corpus)\n",
    "    small_corpus = []\n",
    "    \n",
    "    for sentence in corpus:\n",
    "        small_sentence = []\n",
    "        \n",
    "        for word in sentence:\n",
    "            if word_counts[word] != 1:\n",
    "                small_sentence.append(word)\n",
    "            else:\n",
    "                small_sentence.append(\"-LOW-\")\n",
    "        small_corpus.append(small_sentence)\n",
    "    return small_corpus\n",
    "\n",
    "    \n",
    "train_source = read_corpus(\"training/hansards.36.2.e\", True)\n",
    "train_source = reduce_corpus(train_source)\n",
    "print(\"Read training source corpus\")\n",
    "train_target = read_corpus(\"training/hansards.36.2.f\", False)\n",
    "train_target = reduce_corpus(train_target)\n",
    "print(\"Read training target corpus\")\n",
    "val_source = read_corpus(\"validation/dev.e\", True)\n",
    "val_target = read_corpus(\"validation/dev.f\", False)\n",
    "print(\"Read validation corpora\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11% (228 of 2000) |##                    | Elapsed Time: 0:00:00 ETA:  0:00:01"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialising parameters...\n",
      "Iteration #0 out of 9\n",
      "Doing E-step...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (2000 of 2000) |#####################| Elapsed Time: 0:00:01 Time: 0:00:01\n",
      "100% (2444 of 2444) |#####################| Elapsed Time: 0:00:00 Time: 0:00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doing M-step...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8% (178 of 2000) |#                     | Elapsed Time: 0:00:00 ETA:  0:00:01"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.518597236981934\n",
      "Iteration #1 out of 9\n",
      "Doing E-step...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (2000 of 2000) |#####################| Elapsed Time: 0:00:01 Time: 0:00:01\n",
      "100% (2444 of 2444) |#####################| Elapsed Time: 0:00:00 Time: 0:00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doing M-step...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13% (279 of 2000) |###                   | Elapsed Time: 0:00:00 ETA:  0:00:00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4720430107526882\n",
      "Iteration #2 out of 9\n",
      "Doing E-step...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (2000 of 2000) |#####################| Elapsed Time: 0:00:01 Time: 0:00:01\n",
      "100% (2444 of 2444) |#####################| Elapsed Time: 0:00:00 Time: 0:00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doing M-step...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15% (304 of 2000) |###                   | Elapsed Time: 0:00:00 ETA:  0:00:00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.47634408602150535\n",
      "Iteration #3 out of 9\n",
      "Doing E-step...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (2000 of 2000) |#####################| Elapsed Time: 0:00:01 Time: 0:00:01\n",
      "100% (2444 of 2444) |#####################| Elapsed Time: 0:00:00 Time: 0:00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doing M-step...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11% (228 of 2000) |##                    | Elapsed Time: 0:00:00 ETA:  0:00:00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.48064516129032253\n",
      "Iteration #4 out of 9\n",
      "Doing E-step...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (2000 of 2000) |#####################| Elapsed Time: 0:00:01 Time: 0:00:01\n",
      "100% (2444 of 2444) |#####################| Elapsed Time: 0:00:00 Time: 0:00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doing M-step...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15% (304 of 2000) |###                   | Elapsed Time: 0:00:00 ETA:  0:00:00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.43795620437956206\n",
      "Iteration #5 out of 9\n",
      "Doing E-step...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (2000 of 2000) |#####################| Elapsed Time: 0:00:01 Time: 0:00:01\n",
      "100% (2444 of 2444) |#####################| Elapsed Time: 0:00:00 Time: 0:00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doing M-step...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15% (304 of 2000) |###                   | Elapsed Time: 0:00:00 ETA:  0:00:00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.43169968717413976\n",
      "Iteration #6 out of 9\n",
      "Doing E-step...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (2000 of 2000) |#####################| Elapsed Time: 0:00:01 Time: 0:00:01\n",
      "100% (2444 of 2444) |#####################| Elapsed Time: 0:00:00 Time: 0:00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doing M-step...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13% (279 of 2000) |###                   | Elapsed Time: 0:00:00 ETA:  0:00:01"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4369134515119917\n",
      "Iteration #7 out of 9\n",
      "Doing E-step...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (2000 of 2000) |#####################| Elapsed Time: 0:00:01 Time: 0:00:01\n",
      "100% (2444 of 2444) |#####################| Elapsed Time: 0:00:00 Time: 0:00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doing M-step...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11% (228 of 2000) |##                    | Elapsed Time: 0:00:00 ETA:  0:00:01"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.44525547445255476\n",
      "Iteration #8 out of 9\n",
      "Doing E-step...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (2000 of 2000) |#####################| Elapsed Time: 0:00:01 Time: 0:00:01\n",
      "100% (2444 of 2444) |#####################| Elapsed Time: 0:00:00 Time: 0:00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doing M-step...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13% (279 of 2000) |###                   | Elapsed Time: 0:00:00 ETA:  0:00:00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.45151199165797706\n",
      "Iteration #9 out of 9\n",
      "Doing E-step...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (2000 of 2000) |#####################| Elapsed Time: 0:00:01 Time: 0:00:01\n",
      "100% (2444 of 2444) |#####################| Elapsed Time: 0:00:00 Time: 0:00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doing M-step...\n",
      "0.45359749739311783\n"
     ]
    }
   ],
   "source": [
    "def initialise_parameters(source_corpus, target_corpus):\n",
    "    \"\"\"\n",
    "    Initialises the conditional probability of generating a source \n",
    "    word from a target word for all possible pairs of words in the source \n",
    "    and target sentences to 5 and then normalises the parameters such that \n",
    "    the initialisation is uniform.\n",
    "    \"\"\"\n",
    "    \n",
    "    flat_corpus = [word for sentence in source_corpus for word in sentence]\n",
    "    amount_source_words = len(set(flat_corpus))\n",
    "    theta0 = 1/amount_source_words\n",
    "    return defaultdict(lambda: defaultdict(lambda: theta0))\n",
    "\n",
    "\n",
    "def expectation_maximisation(train_source, train_target, val_source,\n",
    "                             val_target, parameters, num_iterations, \n",
    "                             min_perplexity_change):\n",
    "    \"\"\"\n",
    "    Do the EM algorithm until perplexity decreases very little or until \n",
    "    the number of iterations is reached.\n",
    "    \"\"\"\n",
    "    \n",
    "    old_perplexity = -100000\n",
    "    perplexities = []\n",
    "    aers = []\n",
    "    \n",
    "    for k in range(0, num_iterations):\n",
    "        print(\"Iteration #\" + str(k), \"out of\", num_iterations - 1)\n",
    "        counts_single = defaultdict(lambda: 1.0)\n",
    "        counts_pairs = defaultdict(lambda: defaultdict(float))\n",
    "        counts_single, counts_pairs = e_step(train_source, train_target,\n",
    "                                             parameters, counts_single, \n",
    "                                             counts_pairs)\n",
    "        parameters = m_step(parameters, counts_single, counts_pairs)\n",
    "        perplexity = compute_perplexity(parameters, train_source, train_target)\n",
    "        alignments = get_best_alignment(val_source, val_target, parameters)\n",
    "        aers.append(compute_aer(alignments))\n",
    "        perplexities.append(perplexity)\n",
    "        \n",
    "        if abs(perplexity - old_perplexity) < min_perplexity_change:\n",
    "            return perplexities, aers\n",
    "        else:\n",
    "            old_perplexity = perplexity\n",
    "    return perplexities, aers\n",
    "    \n",
    "    \n",
    "def e_step(source_corpus, target_corpus, parameters, counts_single, \n",
    "           counts_pairs):\n",
    "    \"\"\"\n",
    "    Do the E-step by computing the expected counts.\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"Doing E-step...\")\n",
    "    \n",
    "    with progressbar.ProgressBar(max_value=len(target_corpus)) as bar:\n",
    "        for n in range(len(target_corpus)):\n",
    "            target_sentence = target_corpus[n]\n",
    "            source_sentence = source_corpus[n]\n",
    "\n",
    "            for i in range(len(target_sentence)):\n",
    "                normalisation_term = 0\n",
    "                target_word = target_sentence[i]\n",
    "\n",
    "                for j in range(len(source_sentence)):\n",
    "                    source_word = source_sentence[j]\n",
    "                    normalisation_term += parameters[source_word][target_word]\n",
    "                for j in range(len(source_sentence)):\n",
    "                    source_word = source_sentence[j]\n",
    "                    expected_count = parameters[source_word][target_word]/normalisation_term\n",
    "                    counts_pairs[source_word][target_word] += expected_count\n",
    "                    counts_single[source_word] += expected_count\n",
    "            bar.update(n)\n",
    "    return counts_single, counts_pairs\n",
    "\n",
    "\n",
    "def m_step(parameters, counts_single, counts_pairs):\n",
    "    \"\"\"\n",
    "    Do the M-step by normalising the parameters.\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"Doing M-step...\")\n",
    "    \n",
    "    with progressbar.ProgressBar(max_value=len(counts_pairs)) as bar:\n",
    "        i = 0\n",
    "        for source_word, target_words in counts_pairs.items():\n",
    "            for target_word, expected_count in target_words.items():\n",
    "                parameters[source_word][target_word] = expected_count/counts_single[source_word]\n",
    "            i += 1\n",
    "            bar.update(i)\n",
    "    return parameters\n",
    "\n",
    "\n",
    "def compute_perplexity(parameters, source_corpus, target_corpus):\n",
    "    \"\"\"\n",
    "    Computes the perplexity of the corpus.\n",
    "    \"\"\"\n",
    "    \n",
    "    perplexity = 0\n",
    "    \n",
    "    for n in range(len(source_corpus)):\n",
    "        source_sentence = source_corpus[n]\n",
    "        target_sentence = target_corpus[n]\n",
    "        log_sentence = 0\n",
    "        \n",
    "        for target_word in target_sentence: \n",
    "            log_sum = []\n",
    "            \n",
    "            for source_word in source_sentence: \n",
    "                log_sum.append(parameters[source_word][target_word])\n",
    "            log_sentence += np.log(np.sum(log_sum))\n",
    "        perplexity += log_sentence\n",
    "    return perplexity\n",
    "   \n",
    "    \n",
    "def get_best_alignment(source_corpus, target_corpus, parameters):\n",
    "    \"\"\"\n",
    "    Gets the best alignment for each sentence and saves the alignment\n",
    "    in a list of lists that holds tuples for each position in the sentence\n",
    "    and looks as follows:\n",
    "    (sentence_index, target_word_index, source_word_index).\n",
    "    \"\"\"\n",
    "    \n",
    "    alignments = []\n",
    "    \n",
    "    for n in range(len(source_corpus)):\n",
    "        source_sentence = source_corpus[n]\n",
    "        target_sentence = target_corpus[n]\n",
    "        alignment = []\n",
    "        \n",
    "        for i in range(len(target_sentence)):\n",
    "            target_word = target_sentence[i]\n",
    "            best_prob = 0\n",
    "            best_j = 0\n",
    "            \n",
    "            for j in range(len(source_sentence)):\n",
    "                source_word = source_sentence[j]\n",
    "                prob = parameters[source_word][target_word]\n",
    "                \n",
    "                if prob > best_prob:\n",
    "                    best_prob = prob\n",
    "                    best_j = j\n",
    "                    \n",
    "            if best_j != 0:    \n",
    "                alignment.append((n, best_j, i+1))\n",
    "        alignments.append(alignment)\n",
    "    return alignments\n",
    "\n",
    "\n",
    "def compute_aer(predictions):\n",
    "    \"\"\"\n",
    "    Computes the Alignment Error Rate.\n",
    "    \"\"\"\n",
    "    \n",
    "    gold_sets = aer.read_naacl_alignments(\"validation/dev.wa.nonullalign\")\n",
    "    metric = aer.AERSufficientStatistics()\n",
    "    \n",
    "    for gold, prediction in zip(gold_sets, predictions):\n",
    "        prediction = set([(alignment[1], alignment[2]) for alignment in prediction])\n",
    "        metric.update(sure=gold[0], probable=gold[1], predicted=prediction)\n",
    "    print(metric.aer())\n",
    "    return metric.aer()\n",
    "\n",
    "\n",
    "def save_results(perplexities, aers, file_path):\n",
    "    \"\"\"\n",
    "    Saves the obtained results in a text file.\n",
    "    \"\"\"\n",
    "    \n",
    "    with open(file_path, \"w\") as f:\n",
    "        f.write(\"perplexity\\n\")\n",
    "        \n",
    "        for perplexity in perplexities:\n",
    "            f.write(str(perplexity) + \"\\n\")\n",
    "        \n",
    "        f.write(\"\\naer\\n\")\n",
    "        for aer in aers:\n",
    "            f.write(str(aer) + \"\\n\")\n",
    "    f.close()\n",
    "        \n",
    "    \n",
    "print(\"Initialising parameters...\")\n",
    "initial_params = initialise_parameters(train_source, train_target)\n",
    "perplexities, aers = expectation_maximisation(train_source, train_target, \n",
    "                                              val_source, val_target,\n",
    "                                              initial_params, 10, 5)\n",
    "save_results(perplexities, aers, \"results.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZ0AAAEWCAYAAAC9qEq5AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f48734f5940>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEWCAYAAACXGLsWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f487a33b9b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.arange(1, len(perplexities)+1), perplexities)\n",
    "plt.title(\"Evolution of perplexity\")\n",
    "plt.xlabel(\"Iterations\")\n",
    "plt.ylabel(\"Perplexity\")\n",
    "plt.show()\n",
    "\n",
    "plt.plot(np.arange(1, len(aers)+1), aers)\n",
    "plt.title(\"Evolution of AER\")\n",
    "plt.xlabel(\"Iterations\")\n",
    "plt.ylabel(\"AER\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>IBM Model 2</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration #0 out of 9\n",
      "-43825.68798942278\n",
      "Iteration #1 out of 9\n",
      "-27689.96652975563\n",
      "Iteration #2 out of 9\n",
      "-20140.260034287454\n",
      "Iteration #3 out of 9\n",
      "-16639.441385113078\n",
      "Iteration #4 out of 9\n",
      "-14863.12229544579\n",
      "Iteration #5 out of 9\n",
      "-13857.374375382915\n",
      "Iteration #6 out of 9\n",
      "-13236.110029144236\n",
      "Iteration #7 out of 9\n",
      "-12827.17973242312\n",
      "Iteration #8 out of 9\n",
      "-12545.325750864758\n",
      "Iteration #9 out of 9\n",
      "-12343.937888886425\n",
      "0.45473465140478664\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.45473465140478664"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iterations = 10\n",
    "sub = 1\n",
    "\n",
    "\n",
    "def expectation_maximisation2(source_corpus, target_corpus, parameters, \n",
    "                              num_iterations, min_perplexity_change):\n",
    "    \"\"\"\n",
    "    Runs the EM algorithm for IBM Model 2.\n",
    "    \"\"\"\n",
    "    \n",
    "    q = defaultdict(lambda: defaultdict(lambda: defaultdict(lambda: defaultdict(lambda: 0.1))))\n",
    "    old_perplexity = -100000\n",
    "    \n",
    "    for k in range(0, num_iterations):\n",
    "        print(\"Iteration #\" + str(k), \"out of\", num_iterations - 1)\n",
    "        \n",
    "        counts_pairs = defaultdict(lambda: defaultdict(lambda: 0.))\n",
    "        counts_alignments = defaultdict(lambda: defaultdict(lambda: defaultdict(lambda: defaultdict(lambda: 0.))))\n",
    "        counts_single = defaultdict(lambda: 0.)\n",
    "        counts_pairs, counts_single, counts_alignments = e_step2(source_corpus, target_corpus, \n",
    "                                                                 counts_pairs, counts_single, \n",
    "                                                                 counts_alignments, q)\n",
    "        parameters, q = m_step2(parameters, q, counts_alignments, counts_pairs, counts_single)\n",
    "        perplexity = compute_perplexity2(parameters, q, source_corpus, target_corpus)\n",
    "        \n",
    "        if abs(perplexity - old_perplexity) < min_perplexity_change:\n",
    "            return parameters\n",
    "        else:\n",
    "            old_perplexity = perplexity\n",
    "    return parameters        \n",
    "\n",
    "\n",
    "def e_step2(source_corpus, target_corpus, counts_pairs, counts_single, counts_alignments, q):\n",
    "    \"\"\"\n",
    "    Does the E-step for IBM Model 2.\n",
    "    \"\"\"\n",
    "\n",
    "    for n in range(len(source_corpus)):\n",
    "        source_sentence = source_corpus[n]\n",
    "        target_sentence = target_corpus[n]\n",
    "        l = len(source_sentence)\n",
    "        m = len(target_sentence)\n",
    "\n",
    "        for i, target_word in enumerate(target_sentence):\n",
    "            delta_denominator = sum([parameters[source_sentence[j_k]][target_word] for j_k in range(l)])\n",
    "#             delta_denominator = sum([q[j_k][i][l][m]*parameters[source_sentence[j_k]][target_word] for j_k in range(l)])\n",
    "\n",
    "            for j, source_word in enumerate(source_sentence):\n",
    "#                 delta = (q[j][i][l][m]*parameters[source_word][target_word]) / delta_denominator\n",
    "                delta = parameters[source_word][target_word]/delta_denominator\n",
    "\n",
    "                counts_pairs[source_word][target_word] += delta\n",
    "                counts_single[source_word] += delta\n",
    "                counts_alignments[l][m][i][j] += delta\n",
    "    return counts_pairs, counts_single, counts_alignments\n",
    "\n",
    "\n",
    "def m_step2(parameters, q, counts_alignments, counts_pairs, counts_single):\n",
    "    \"\"\"\n",
    "    Does the M-step for IBM Model 2.\n",
    "    \"\"\"\n",
    "    \n",
    "    for j in q.keys():\n",
    "        for i in q[j].keys():\n",
    "            for l in q[j][i].keys():\n",
    "                for m in q[j][i][l].keys():\n",
    "                    q[j][i][l][m] = counts_alignments[l][m][i][j] / sum(counts_alignments[l][m][i].values())\n",
    "    \n",
    "    for source_word, target_words in parameters.items():\n",
    "        for target_word in target_words:\n",
    "            parameters[source_word][target_word] = counts_pairs[source_word][target_word]/counts_single[source_word]\n",
    "    return parameters, q\n",
    "\n",
    "\n",
    "def compute_perplexity2(parameters, q, source_corpus, target_corpus):\n",
    "    \"\"\"\n",
    "    Computes the perplexity of the corpus for IBM Model 2.\n",
    "    \"\"\"\n",
    "    \n",
    "    perplexity = 0\n",
    "    \n",
    "    for n in range(len(source_corpus)):\n",
    "        source_sentence = source_corpus[n]\n",
    "        target_sentence = target_corpus[n]\n",
    "        log_sentence = 0\n",
    "        \n",
    "        for target_word in target_sentence: \n",
    "            log_sum = []\n",
    "            \n",
    "            for source_word in source_sentence: \n",
    "                log_sum.append(parameters[source_word][target_word])\n",
    "            log_sentence += np.log(np.sum(log_sum))\n",
    "        perplexity += log_sentence\n",
    "    print(perplexity)\n",
    "    return perplexity\n",
    "    \n",
    "\n",
    "parameters = initialise_parameters(train_source, train_target)\n",
    "parameters = expectation_maximisation2(train_source, train_target, parameters, \n",
    "                                       10, 5)\n",
    "alignments = get_best_alignment(val_source, val_target, parameters)\n",
    "compute_aer(alignments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variational Bayes IBM1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 th iteration out of  9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tirza/.local/lib/python3.6/site-packages/ipykernel_launcher.py:111: RuntimeWarning: divide by zero encountered in log\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-inf\n",
      "-inf\n",
      "1 th iteration out of  9\n",
      "-35971.71626889991\n",
      "-157037996.0695538\n",
      "2 th iteration out of  9\n",
      "-35202.56378257411\n",
      "-158995845.25507936\n",
      "3 th iteration out of  9\n",
      "-35169.57919076955\n",
      "-159090048.60621175\n",
      "4 th iteration out of  9\n",
      "-35166.35835046255\n",
      "-159100017.14260536\n",
      "5 th iteration out of  9\n",
      "-35165.86683824031\n",
      "-159101597.3414697\n",
      "6 th iteration out of  9\n",
      "-35165.77598545139\n",
      "-159101897.34031513\n",
      "7 th iteration out of  9\n",
      "-35165.75771597888\n",
      "-159101959.2001269\n",
      "8 th iteration out of  9\n",
      "-35165.75388054293\n",
      "-159101972.48514116\n",
      "9 th iteration out of  9\n",
      "-35165.753054372166\n",
      "-159101975.40174392\n"
     ]
    }
   ],
   "source": [
    "def elbo(theta_dict, lambda_dict, train_source, train_target, alpha):\n",
    "\n",
    "    elbo_first_term = compute_perplexity(theta_dict, train_source, train_target)\n",
    "    elbo_second_term = 0\n",
    "\n",
    "    for english_word in english_vocab: \n",
    "        normalization = sum([lambda_dict[english_word][french_word] for french_word in french_vocab])\n",
    "        digamma_normalization = digamma(normalization)\n",
    "        gammaln_normalization = gammaln(normalization)\n",
    "        for french_word in french_vocab: \n",
    "            first_term = digamma(lambda_dict[english_word][french_word]) - digamma_normalization \n",
    "            first_term = first_term * (alpha - lambda_dict[english_word][french_word])\n",
    "            second_term = gammaln(lambda_dict[english_word][french_word]) \n",
    "            third_term = gammaln(alpha)\n",
    "            fourth_term = gammaln(len(french_vocab) * alpha)\n",
    "            elbo_second_term += first_term + second_term - third_term + fourth_term - gammaln_normalization\n",
    "\n",
    "    return elbo_first_term + elbo_second_term\n",
    "\n",
    "\n",
    "alpha = 1\n",
    "iterations = 10 \n",
    "\n",
    "theta_dict = initialise_parameters(train_source, train_target)\n",
    "lambda_dict = initialise_parameters(train_source, train_target)\n",
    "\n",
    "english_vocab = set([word for sentence in train_source for word in sentence])\n",
    "french_vocab = set([word for sentence in train_target for word in sentence])\n",
    "\n",
    "for i in range(iterations): \n",
    "    print(i, 'th iteration out of ', iterations-1)\n",
    "    counts_single = defaultdict(lambda: 1.0)\n",
    "    counts_pairs = defaultdict(lambda: defaultdict(float))\n",
    "    \n",
    "    # e step\n",
    "    for n in range(len(train_source)):\n",
    "        source_sentence = train_source[n]\n",
    "        target_sentence = train_target[n]\n",
    "        \n",
    "        for source_word in source_sentence: \n",
    "            normalization = sum([lambda_dict[source_word][target_word] for target_word in target_sentence])\n",
    "            for target_word in target_sentence: \n",
    "                theta_dict[source_word][target_word] = np.exp(digamma(lambda_dict[source_word][target_word]) - \\\n",
    "                                                              digamma(normalization))\n",
    "    # m step    \n",
    "    for source_word in english_vocab: \n",
    "        target_words = lambda_dict[source_word].keys()\n",
    "        for target_word in target_words:\n",
    "            lambda_dict[source_word][target_word] = alpha + theta_dict[source_word][target_word]\n",
    "    \n",
    "    elbo_iter = elbo(theta_dict, lambda_dict, train_source, train_target, alpha)\n",
    "    print(elbo_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sénat\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0160222191049944"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import operator \n",
    "\n",
    "print(max(lambda_dict['the'].items(), key=operator.itemgetter(1))[0])\n",
    "lambda_dict['the']['sénateurs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-19030.957387138806"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_perplexity(theta_dict, train_source, train_target)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
