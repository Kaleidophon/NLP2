{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>**IBM Model 1**</h1>\n",
    "\n",
    "1. a) Implement EM training (Brown et al., 1993) for IBM model 1; <br />\n",
    "    b) Implement variational inference for Bayesian IBM model 1; <br />\n",
    "    c) All of the tasks below should be performed for both models.<br />\n",
    "2. Plot the evolution of training log likelihood (or ELBO) as a function of the iteration.\n",
    "3. Plot the evolution of alignment error rate (AER) on validation data as a function of the iteration;\n",
    "4. Experiment with two criteria for model selection (i.e. deciding on number of training iterations): \n",
    "    1) convergence in terms of training log likelihood; \n",
    "    2) best AER on validation data;\n",
    "5. For the selected models, obtain Viterbi alignments for every sentence pair in a test\n",
    "corpus and compute AER using a gold-standard provided by the assistant;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import aer\n",
    "from collections import defaultdict, Counter\n",
    "import json\n",
    "from math import log2\n",
    "import numpy as np\n",
    "from random import randint\n",
    "import random\n",
    "import progressbar\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.special import digamma, gammaln \n",
    "import os\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read training source corpus\n",
      "Read training target corpus\n",
      "Read validation corpora\n",
      "Read test corpora\n"
     ]
    }
   ],
   "source": [
    "def read_corpus(file_name, source_language):\n",
    "    \"\"\"\n",
    "    Reads the corpus and saves each sentence in a list.\n",
    "    \"\"\"\n",
    "    \n",
    "    corpus = []\n",
    "    \n",
    "    with open(file_name, \"r\", encoding='utf8') as f:\n",
    "        for line in f:\n",
    "            line = line.replace(\"\\n\", \"\")\n",
    "            sentence = line.split()\n",
    "            \n",
    "            if source_language:\n",
    "                sentence.insert(0, \"null\")\n",
    "            corpus.append(sentence)\n",
    "    return corpus\n",
    "\n",
    "\n",
    "def reduce_corpus(corpus):\n",
    "    \"\"\"\n",
    "    Reduces the vocabulary of the corpus by replacing each word that only\n",
    "    occurs once in the vocabulary by -LOW- in the corpus.\n",
    "    \"\"\"\n",
    "    \n",
    "    flat_corpus = [word for sentence in corpus for word in sentence]\n",
    "    word_counts = Counter(flat_corpus)\n",
    "    small_corpus = []\n",
    "    \n",
    "    for sentence in corpus:\n",
    "        small_sentence = []\n",
    "        \n",
    "        for word in sentence:\n",
    "            if word_counts[word] != 1:\n",
    "                small_sentence.append(word)\n",
    "            else:\n",
    "                small_sentence.append(\"-LOW-\")\n",
    "        small_corpus.append(small_sentence)\n",
    "    return small_corpus\n",
    "\n",
    "    \n",
    "train_source = read_corpus(\"training/hansards.36.2.e\", True)\n",
    "train_source = reduce_corpus(train_source)\n",
    "print(\"Read training source corpus\")\n",
    "train_target = read_corpus(\"training/hansards.36.2.f\", False)\n",
    "train_target = reduce_corpus(train_target)\n",
    "print(\"Read training target corpus\")\n",
    "val_source = read_corpus(\"validation/dev.e\", True)\n",
    "val_target = read_corpus(\"validation/dev.f\", False)\n",
    "print(\"Read validation corpora\")\n",
    "test_source = read_corpus(\"testing/test/test.e\", True)\n",
    "test_target = read_corpus(\"testing/test/test.f\", False)\n",
    "print(\"Read test corpora\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def initialise_parameters(source_corpus, target_corpus, method):\n",
    "    \"\"\"\n",
    "    Initialises the conditional probability of generating a source \n",
    "    word from a target word for all possible pairs of words in the source \n",
    "    and target sentences to 5 and then normalises the parameters such that \n",
    "    the initialisation is uniform.\n",
    "    \"\"\"\n",
    "    \n",
    "    if method == \"uniform\":\n",
    "        vocabulary = set([word for sentence in source_corpus for word in sentence])\n",
    "        theta0 = 1/len(vocabulary)\n",
    "        return defaultdict(lambda: defaultdict(lambda: theta0))\n",
    "    elif method == \"random\":\n",
    "        theta0 = np.random.uniform(0.001, 1)\n",
    "        return defaultdict(lambda: defaultdict(lambda: theta0))\n",
    "    elif method == \"ibm1\":\n",
    "        file_path = get_best_aer()\n",
    "        parameters = load_parameters(file_path)\n",
    "        return parameters      \n",
    "\n",
    "\n",
    "def expectation_maximisation(train_source, train_target, val_source,\n",
    "                             val_target, parameters, num_iterations, \n",
    "                             min_perplexity_change, model):\n",
    "    \"\"\"\n",
    "    Do the EM algorithm until perplexity decreases very little or until \n",
    "    the number of iterations is reached.\n",
    "    \"\"\"\n",
    "    \n",
    "    old_perplexity = -100000\n",
    "    perplexities = []\n",
    "    aers = []\n",
    "    best_aer = 1\n",
    "    best_parameters = parameters\n",
    "    \n",
    "    for k in range(0, num_iterations):\n",
    "        print(\"Iteration #\" + str(k), \"out of\", num_iterations - 1)\n",
    "        counts_single = defaultdict(lambda: 1.0)\n",
    "        counts_pairs = defaultdict(lambda: defaultdict(float))\n",
    "        counts_single, counts_pairs = e_step(train_source, train_target,\n",
    "                                             parameters, counts_single, \n",
    "                                             counts_pairs)\n",
    "        parameters = m_step(parameters, counts_single, counts_pairs)\n",
    "        perplexity = compute_perplexity(parameters, train_source, train_target)\n",
    "        alignments = get_best_alignment(val_source, val_target, parameters)\n",
    "        val_aer = compute_aer(alignments, \"validation/dev.wa.nonullalign\")\n",
    "        aers.append(val_aer)\n",
    "        perplexities.append(perplexity)\n",
    "        \n",
    "        # Convergence in terms of training log likelihood\n",
    "        if model == \"likelihood\":\n",
    "            if abs(perplexity - old_perplexity) < min_perplexity_change:\n",
    "                return perplexities, aers, best_parameters\n",
    "            else:\n",
    "                old_perplexity = perplexity\n",
    "                best_parameters = parameters\n",
    "        # Convergence in terms of best AER on validation data\n",
    "        elif model == \"aer\":\n",
    "            if val_aer < best_aer:\n",
    "                best_aer = val_aer\n",
    "                best_parameters = parameters\n",
    "            else:\n",
    "                return perplexities, aers, best_parameters\n",
    "    return perplexities, aers, parameters\n",
    "    \n",
    "    \n",
    "def e_step(source_corpus, target_corpus, parameters, counts_single, \n",
    "           counts_pairs):\n",
    "    \"\"\"\n",
    "    Do the E-step by computing the expected counts.\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"Doing E-step...\")\n",
    "    \n",
    "    with progressbar.ProgressBar(max_value=len(target_corpus)) as bar:\n",
    "        for n in range(len(target_corpus)):\n",
    "            target_sentence = target_corpus[n]\n",
    "            source_sentence = source_corpus[n]\n",
    "\n",
    "            for i in range(len(target_sentence)):\n",
    "                normalisation_term = 0\n",
    "                target_word = target_sentence[i]\n",
    "\n",
    "                for j in range(len(source_sentence)):\n",
    "                    source_word = source_sentence[j]\n",
    "                    normalisation_term += parameters[source_word][target_word]\n",
    "                for j in range(len(source_sentence)):\n",
    "                    source_word = source_sentence[j]\n",
    "                    expected_count = parameters[source_word][target_word]/normalisation_term\n",
    "                    counts_pairs[source_word][target_word] += expected_count\n",
    "                    counts_single[source_word] += expected_count\n",
    "            bar.update(n)\n",
    "    return counts_single, counts_pairs\n",
    "\n",
    "\n",
    "def m_step(parameters, counts_single, counts_pairs):\n",
    "    \"\"\"\n",
    "    Do the M-step by normalising the parameters.\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"Doing M-step...\")\n",
    "    \n",
    "    with progressbar.ProgressBar(max_value=len(counts_pairs)) as bar:\n",
    "        i = 0\n",
    "        for source_word, target_words in counts_pairs.items():\n",
    "            for target_word, expected_count in target_words.items():\n",
    "                parameters[source_word][target_word] = expected_count/counts_single[source_word]\n",
    "            i += 1\n",
    "            bar.update(i)\n",
    "    return parameters\n",
    "\n",
    "\n",
    "def compute_perplexity(parameters, source_corpus, target_corpus):\n",
    "    \"\"\"\n",
    "    Computes the perplexity of the corpus.\n",
    "    \"\"\"\n",
    "    \n",
    "    perplexity = 0\n",
    "    \n",
    "    for n in range(len(source_corpus)):\n",
    "        source_sentence = source_corpus[n]\n",
    "        target_sentence = target_corpus[n]\n",
    "        log_sentence = 0\n",
    "        \n",
    "        for target_word in target_sentence: \n",
    "            log_sum = []\n",
    "            \n",
    "            for source_word in source_sentence: \n",
    "                log_sum.append(parameters[source_word][target_word])\n",
    "            log_sentence += np.log(np.sum(log_sum))\n",
    "        perplexity += log_sentence\n",
    "    print(perplexity)\n",
    "    return perplexity\n",
    "   \n",
    "\n",
    "def get_best_alignment(source_corpus, target_corpus, parameters):\n",
    "    \"\"\"\n",
    "    Gets the best alignment for each sentence and saves the alignment\n",
    "    in a list of lists that holds tuples for each position in the sentence\n",
    "    and looks as follows:\n",
    "    (sentence_index, target_word_index, source_word_index).\n",
    "    \"\"\"\n",
    "    alignments = []\n",
    "    \n",
    "    print(\"Getting alignments...\")\n",
    "    \n",
    "    with progressbar.ProgressBar(max_value=len(target_corpus)) as bar:\n",
    "        for n in range(len(source_corpus)):\n",
    "            source_sentence = source_corpus[n]\n",
    "            target_sentence = target_corpus[n]\n",
    "            alignment = []\n",
    "\n",
    "            for i, target_word in enumerate(target_sentence):\n",
    "                best_prob = 0\n",
    "                best_j = 0\n",
    "\n",
    "                for j, source_word in enumerate(source_sentence):\n",
    "                    # If a word does not occur in the training data, assign probability 0\n",
    "                    prob = parameters[source_word].get(target_word, 0)\n",
    "\n",
    "                    if prob > best_prob:\n",
    "                        best_prob = prob\n",
    "                        best_j = j\n",
    "\n",
    "                if best_j != 0:    \n",
    "                    alignment.append((n, best_j, i+1))\n",
    "            alignments.append(alignment)\n",
    "            bar.update(n)\n",
    "    return alignments\n",
    "\n",
    "\n",
    "def compute_aer(predictions, file_path):\n",
    "    \"\"\"\n",
    "    Computes the Alignment Error Rate.\n",
    "    \"\"\"\n",
    "    \n",
    "    gold_sets = aer.read_naacl_alignments(file_path)\n",
    "    metric = aer.AERSufficientStatistics()\n",
    "    \n",
    "    for gold, prediction in zip(gold_sets, predictions):\n",
    "        prediction = set([(alignment[1], alignment[2]) for alignment in prediction])\n",
    "        metric.update(sure=gold[0], probable=gold[1], predicted=prediction)\n",
    "    print(metric.aer())\n",
    "    return metric.aer()\n",
    "\n",
    "\n",
    "def save_results(perplexities, aers, file_path):\n",
    "    \"\"\"\n",
    "    Saves the obtained results in a text file.\n",
    "    \"\"\"\n",
    "    \n",
    "    with open(file_path, \"w\") as f:\n",
    "        f.write(\"perplexity\\n\")\n",
    "        \n",
    "        for perplexity in perplexities:\n",
    "            f.write(str(perplexity) + \"\\n\")\n",
    "        \n",
    "        f.write(\"\\naer\\n\")\n",
    "        for aer in aers:\n",
    "            f.write(str(aer) + \"\\n\")\n",
    "    f.close()\n",
    "\n",
    "    \n",
    "def save_parameters(file_path, parameters):\n",
    "    \"\"\"\n",
    "    Saves the parameters in a Pickle file.\n",
    "    \"\"\"\n",
    "    \n",
    "    data = json.loads(json.dumps(parameters))\n",
    "    f = open(file_path, \"wb\")\n",
    "    pickle.dump(data, f)\n",
    "    f.close()\n",
    "    \n",
    "\n",
    "def load_parameters(file_path):\n",
    "    \"\"\"\n",
    "    Loads the parameters that obtained the highest validation AER\n",
    "    from a Pickle file.\n",
    "    \"\"\"\n",
    "    \n",
    "    f = open(file_path, \"rb\")\n",
    "    parameters = pickle.load(pkl_file)\n",
    "    f.close()\n",
    "    return parameters\n",
    "\n",
    "\n",
    "def get_best_aer():\n",
    "    \"\"\"\n",
    "    Finds the file that had the highest AER score and returns the file path.\n",
    "    \"\"\"\n",
    "    \n",
    "    dir_path = os.path.dirname(os.path.realpath(__file__))\n",
    "    files = [f for f in os.listdir(dir_path) if f.endswith(\".pkl\")]\n",
    "    best_aer = 0\n",
    "    \n",
    "    for f in files:\n",
    "        file_name = f[:f.rfind(\".\")]\n",
    "        current_aer = float(file_name[file_name.rfind(\"_\")+1:])\n",
    "        \n",
    "        if current_aer > best_aer:\n",
    "            best_aer = current_aer \n",
    "            file_path = f\n",
    "    return file_path    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialising parameters...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0% (157 of 231164) |                    | Elapsed Time: 0:00:00 ETA:  0:02:29"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration #0 out of 9\n",
      "Doing E-step...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96% (221943 of 231164) |################ | Elapsed Time: 0:02:45 ETA:  0:00:06"
     ]
    }
   ],
   "source": [
    "print(\"Initialising parameters...\")\n",
    "model = \"likelihood\"\n",
    "initial_params = initialise_parameters(train_source, train_target, \"uniform\")\n",
    "perplexities, aers, parameters = expectation_maximisation(train_source, train_target, \n",
    "                                                          val_source, val_target,\n",
    "                                                          initial_params, 10, 1000,\n",
    "                                                          model)\n",
    "alignments = get_best_alignment(test_source, test_target, parameters)\n",
    "print(\"aer on test set\")\n",
    "test_aer = compute_aer(alignments, \"testing/answers/test.wa.nonullalign\")\n",
    "# save_results(perplexities, aers, \"ibm1_full_reduced.txt\")\n",
    "file_path = \"ibm1_\" + model + \"_parameters_\" + str(test_aer) + \".pkl\"\n",
    "save_parameters(file_path, parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZ4AAAEZCAYAAACnyUNvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x4c2a0c7f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAEZCAYAAACEkhK6AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x4b065a358>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.arange(1, len(perplexities)+1), perplexities)\n",
    "plt.title(\"Evolution of perplexity\")\n",
    "plt.xlabel(\"Iterations\")\n",
    "plt.ylabel(\"Perplexity\")\n",
    "plt.show()\n",
    "\n",
    "plt.plot(np.arange(1, len(aers)+1), aers)\n",
    "plt.title(\"Evolution of AER\")\n",
    "plt.xlabel(\"Iterations\")\n",
    "plt.ylabel(\"AER\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>IBM Model 2</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration #0 out of 9\n",
      "-180631.830215\n",
      "0.5180972078593589\n",
      "Iteration #1 out of 9\n"
     ]
    },
    {
     "ename": "ZeroDivisionError",
     "evalue": "float division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-348e7b5b94d9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    103\u001b[0m \u001b[0mparameters\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minitialise_parameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_source\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_target\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m parameters = expectation_maximisation2(train_source, train_target, val_source, val_target, parameters, \n\u001b[1;32m--> 105\u001b[1;33m                                        10, 5)\n\u001b[0m",
      "\u001b[1;32m<ipython-input-8-348e7b5b94d9>\u001b[0m in \u001b[0;36mexpectation_maximisation2\u001b[1;34m(source_corpus, target_corpus, val_source, val_target, parameters, num_iterations, min_perplexity_change)\u001b[0m\n\u001b[0;32m     21\u001b[0m                                                                  \u001b[0mcounts_pairs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcounts_single\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m                                                                  counts_alignments, q)\n\u001b[1;32m---> 23\u001b[1;33m         \u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mq\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mm_step2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcounts_alignments\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcounts_pairs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcounts_single\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m         \u001b[0mperplexity\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompute_perplexity2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msource_corpus\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_corpus\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m         \u001b[0malignments\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_best_alignment\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval_source\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_target\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-8-348e7b5b94d9>\u001b[0m in \u001b[0;36mm_step2\u001b[1;34m(parameters, q, counts_alignments, counts_pairs, counts_single)\u001b[0m\n\u001b[0;32m     71\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0msource_word\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_words\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mtarget_word\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtarget_words\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m             \u001b[0mparameters\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0msource_word\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtarget_word\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcounts_pairs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0msource_word\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtarget_word\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mcounts_single\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0msource_word\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mq\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mZeroDivisionError\u001b[0m: float division by zero"
     ]
    }
   ],
   "source": [
    "def expectation_maximisation2(source_corpus, target_corpus, val_source,\n",
    "                              val_target, parameters, num_iterations, \n",
    "                              min_perplexity_change, model, file_path):\n",
    "    \"\"\"\n",
    "    Runs the EM algorithm for IBM Model 2.\n",
    "    \"\"\"\n",
    "    \n",
    "    q = defaultdict(lambda: defaultdict(lambda: defaultdict(lambda: defaultdict(lambda: 0.1))))\n",
    "    old_perplexity = -100000\n",
    "    perplexities = []\n",
    "    aers = []\n",
    "    best_aer = 1\n",
    "    \n",
    "    with open(file_path, \"a\") as f:\n",
    "        for k in range(0, num_iterations):\n",
    "            print(\"Iteration #\" + str(k), \"out of\", num_iterations - 1)\n",
    "\n",
    "            counts_pairs = defaultdict(lambda: defaultdict(lambda: 0))\n",
    "            counts_alignments = defaultdict(lambda: defaultdict(lambda: defaultdict(lambda: defaultdict(lambda: 0))))\n",
    "            counts_single = defaultdict(lambda: 0)\n",
    "            counts_pairs, counts_single, counts_alignments = e_step2(source_corpus, target_corpus, \n",
    "                                                                     counts_pairs, counts_single, \n",
    "                                                                     counts_alignments, q)\n",
    "            parameters, q = m_step2(parameters, q, counts_alignments, counts_pairs, counts_single)\n",
    "            perplexity = compute_perplexity2(parameters, q, source_corpus, target_corpus)\n",
    "            alignments = get_best_alignment(val_source, val_target, parameters)\n",
    "            val_aer = compute_aer(alignments, \"validation/dev.wa.nonullalign\")\n",
    "            f.write(\"pp \" + str(perplexity) + \"\\n\")\n",
    "            f.write(\"aer \" + str(val_aer) + \"\\n\")\n",
    "            perplexities.append(perplexity)\n",
    "            aers.append(val_aer)\n",
    "            \n",
    "            # Convergence in terms of training log likelihood\n",
    "            if model == \"likelihood\":            \n",
    "                if abs(perplexity - old_perplexity) < min_perplexity_change:\n",
    "                    return perplexities, aers\n",
    "                else:\n",
    "                    old_perplexity = perplexity\n",
    "            # Convergence in terms of best AER on validation data\n",
    "            elif model == \"aer\":\n",
    "                if val_aer < best_aer:\n",
    "                    best_aer = val_aer\n",
    "                else:\n",
    "                    return perplexities, aers\n",
    "        f.close()\n",
    "    return perplexities, aers        \n",
    "\n",
    "\n",
    "def e_step2(source_corpus, target_corpus, counts_pairs, counts_single, counts_alignments, q):\n",
    "    \"\"\"\n",
    "    Does the E-step for IBM Model 2.\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"Doing E-step...\")\n",
    "    \n",
    "    with progressbar.ProgressBar(max_value=len(source_corpus)) as bar:\n",
    "        for n in range(len(source_corpus)):\n",
    "            source_sentence = source_corpus[n]\n",
    "            target_sentence = target_corpus[n]\n",
    "            l = len(source_sentence)\n",
    "            m = len(target_sentence)\n",
    "\n",
    "            for i, target_word in enumerate(target_sentence):\n",
    "                delta_denominator = sum([q[j_k][i][l][m]*parameters[source_sentence[j_k]][target_word] \n",
    "                                         for j_k in range(l)])\n",
    "\n",
    "                for j, source_word in enumerate(source_sentence):\n",
    "                    delta = (q[j][i][l][m]*parameters[source_word][target_word])/delta_denominator\n",
    "\n",
    "                    counts_pairs[source_word][target_word] += delta\n",
    "                    counts_single[source_word] += delta\n",
    "                    counts_alignments[l][m][i][j] += delta\n",
    "            bar.update(n)\n",
    "    return counts_pairs, counts_single, counts_alignments\n",
    "\n",
    "\n",
    "def m_step2(parameters, q, counts_alignments, counts_pairs, counts_single):\n",
    "    \"\"\"\n",
    "    Does the M-step for IBM Model 2.\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"Doing M-step...\")\n",
    "    \n",
    "    for j in q.keys():\n",
    "        for i in q[j].keys():\n",
    "            for l in q[j][i].keys():\n",
    "                for m in q[j][i][l].keys():\n",
    "                    q[j][i][l][m] = counts_alignments[l][m][i][j]/sum(counts_alignments[l][m][i].values())\n",
    "    \n",
    "    for source_word, target_words in parameters.items():\n",
    "        for target_word in target_words:\n",
    "            parameters[source_word][target_word] = \\\n",
    "                counts_pairs[source_word][target_word]/counts_single[source_word]\n",
    "    return parameters, q\n",
    "\n",
    "\n",
    "def compute_perplexity2(parameters, q, source_corpus, target_corpus):\n",
    "    \"\"\"\n",
    "    Computes the perplexity of the corpus for IBM Model 2.\n",
    "    \"\"\"\n",
    "    \n",
    "    perplexity = 0\n",
    "    \n",
    "    print(\"Calculating perplexity...\")\n",
    "    \n",
    "    with progressbar.ProgressBar(max_value=len(source_corpus)) as bar:\n",
    "        for n in range(len(source_corpus)):\n",
    "            source_sentence = source_corpus[n]\n",
    "            target_sentence = target_corpus[n]\n",
    "            log_sentence = 0\n",
    "            l = len(source_sentence)\n",
    "            m = len(target_sentence)\n",
    "\n",
    "            for i, target_word in enumerate(target_sentence): \n",
    "                log_sum = []\n",
    "\n",
    "                for j, source_word in enumerate(source_sentence): \n",
    "                    log_sum.append(parameters[source_word][target_word]*q[j][i][l][m])\n",
    "                log_sentence += np.log(np.sum(log_sum))\n",
    "            perplexity += log_sentence\n",
    "            bar.update(n)\n",
    "    print(perplexity)\n",
    "    return perplexity\n",
    "    \n",
    "     \n",
    "parameters = initialise_parameters(train_source, train_target, \"uniform\")\n",
    "perplexities, aers, parameters = expectation_maximisation2(train_source, train_target, \n",
    "                                                           val_source, val_target,\n",
    "                                                           parameters, 10, 1000, \"aer\")\n",
    "alignments = get_best_alignment(test_source, test_target, parameters)\n",
    "print(\"aer on test set\")\n",
    "test_aer = compute_aer(alignments, \"testing/answers/test.wa.nonullalign\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variational Bayes IBM1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 th iteration out of  9\n"
     ]
    }
   ],
   "source": [
    "def elbo(theta_dict, lambda_dict, train_source_corpus, train_target_corpus, alpha):\n",
    "\n",
    "    elbo_first_term = compute_perplexity(theta_dict, train_source_corpus, train_target_corpus)\n",
    "    elbo_second_term = 0\n",
    "\n",
    "    for english_word in english_vocab: \n",
    "        normalization = sum([lambda_dict[english_word][french_word] for french_word in french_vocab])\n",
    "        digamma_normalization = digamma(normalization)\n",
    "        gammaln_normalization = gammaln(normalization)\n",
    "        for french_word in french_vocab: \n",
    "            first_term = digamma(lambda_dict[english_word][french_word]) - digamma_normalization \n",
    "            first_term = first_term * (alpha - lambda_dict[english_word][french_word])\n",
    "            second_term = gammaln(lambda_dict[english_word][french_word]) \n",
    "            third_term = gammaln(alpha)\n",
    "            fourth_term = gammaln(len(french_vocab) * alpha)\n",
    "            elbo_second_term += first_term + second_term - third_term + fourth_term - gammaln_normalization\n",
    "\n",
    "    return elbo_first_term + elbo_second_term\n",
    "\n",
    "\n",
    "alpha = 0.1\n",
    "iterations = 10 \n",
    "\n",
    "theta_dict = defaultdict(lambda: defaultdict(lambda: random.uniform(0.001, 1)))\n",
    "lambda_dict = defaultdict(lambda: defaultdict(lambda: random.uniform(0.001, 1)))\n",
    "\n",
    "english_vocab = set([word for sentence in train_source for word in sentence])\n",
    "french_vocab = set([word for sentence in train_target for word in sentence])\n",
    "\n",
    "elbos = []\n",
    "aers = []\n",
    "\n",
    "for i in range(iterations): \n",
    "    print(i, 'th iteration out of ', iterations-1)\n",
    "    counts_pairs = defaultdict(lambda: defaultdict(float))\n",
    "    \n",
    "    # e step\n",
    "    for n in range(len(train_source)):\n",
    "        source_sentence = train_source[n]\n",
    "        target_sentence = train_target[n]\n",
    "        \n",
    "        for source_word in source_sentence: \n",
    "            normalization = sum([lambda_dict[source_word][target_word] for target_word in target_sentence])\n",
    "            for target_word in target_sentence: \n",
    "                value = np.exp(digamma(lambda_dict[source_word][target_word]) - digamma(normalization))\n",
    "                theta_dict[source_word][target_word] += value\n",
    "                counts_pairs[source_word][target_word] += value\n",
    "    # m step    \n",
    "    for source_word in english_vocab: \n",
    "        target_words = lambda_dict[source_word].keys()\n",
    "        for target_word in target_words:\n",
    "            lambda_dict[source_word][target_word] = alpha + counts_pairs[source_word][target_word]\n",
    "    \n",
    "    elbo_iter = elbo(theta_dict, lambda_dict, train_source, train_target, alpha)\n",
    "    elbos.append(elbo_iter)\n",
    "    print(elbo_iter)\n",
    "    alignment = get_best_alignment(val_source, val_target, theta_dict)\n",
    "    aer_iter = compute_aer(alignment)\n",
    "    aers.append(aer_iter)\n",
    "    print(aer_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sénat\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0160222191049944"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import operator \n",
    "\n",
    "print(max(lambda_dict['the'].items(), key=operator.itemgetter(1))[0])\n",
    "lambda_dict['the']['sénateurs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-19030.957387138806"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_perplexity(theta_dict, train_source, train_target)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
