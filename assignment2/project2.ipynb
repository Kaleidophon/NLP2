{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "plt.switch_backend('agg')\n",
    "import math\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "import time\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LENGTH = 50\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, dropout_p=0.1):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.dropout_p = dropout_p\n",
    "\n",
    "        self.word_embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.pos_embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.dropout = nn.Dropout(self.dropout_p)\n",
    "        self.linear = nn.Linear(hidden_size, hidden_size)\n",
    "        \n",
    "    def forward(self, input, hidden):\n",
    "        embedded_words = self.word_embedding(input).view(1, 1, -1)\n",
    "        embedded_pos = self.pos_embedding(input).view(1, 1, -1)\n",
    "        output = self.dropout(embedded_words + embedded_pos)\n",
    "        \n",
    "        output, hidden = self.linear(output, hidden)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size)\n",
    "\n",
    "    \n",
    "class AttnDecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=MAX_LENGTH):\n",
    "        super(AttnDecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.dropout_p = dropout_p\n",
    "        self.max_length = max_length\n",
    "\n",
    "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
    "        self.attn = nn.Linear(self.hidden_size * 2, self.max_length)\n",
    "        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
    "        self.dropout = nn.Dropout(self.dropout_p)\n",
    "        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n",
    "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
    "\n",
    "    def forward(self, input, hidden, encoder_outputs):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        embedded = self.dropout(embedded)\n",
    "\n",
    "        attn_weights = F.softmax(\n",
    "            self.attn(torch.cat((embedded[0], hidden[0]), 1)), dim=1)\n",
    "        attn_applied = torch.bmm(attn_weights.unsqueeze(0),\n",
    "                                 encoder_outputs.unsqueeze(0))\n",
    "\n",
    "        output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
    "        output = self.attn_combine(output).unsqueeze(0)\n",
    "\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "\n",
    "        output = F.log_softmax(self.out(output[0]), dim=1)\n",
    "        return output, hidden, attn_weights\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(file_name):\n",
    "    \"\"\"\n",
    "    Reads the data and returns it in a list.\n",
    "    \"\"\"\n",
    "    \n",
    "    f = open(file_name, \"r\")\n",
    "    return [line.strip().split() for line in f.readlines()]\n",
    "\n",
    "\n",
    "def word_to_index(file_name):\n",
    "    \"\"\"\n",
    "    Obtains the vocabulary of a file and returns it \n",
    "    in a dictionary to be able to use w2i.\n",
    "    \"\"\"\n",
    "    \n",
    "    file = open(file_name) \n",
    "    w2i = json.load(file)\n",
    "    w2i[\"sos\"] = len(w2i)\n",
    "    return w2i\n",
    "\n",
    "\n",
    "def index_to_word(dictionary):\n",
    "    \"\"\"\n",
    "    Reverses the dictionary such that i2w can be used.\n",
    "    \"\"\"\n",
    "    \n",
    "    reversed_dict = {}\n",
    "    \n",
    "    for word, index in dictionary.items():\n",
    "        reversed_dict[index] = word\n",
    "    reversed_dict[index + 1] = \"sos\" \n",
    "    return reversed_dict\n",
    "\n",
    "\n",
    "def sentence_to_indices(w2i, sentence):\n",
    "    \"\"\"\n",
    "    Returns the indices of the words in a sentence in a list.\n",
    "    \"\"\"\n",
    "    \n",
    "    return [w2i[word] for word in sentence]\n",
    "\n",
    "\n",
    "def sentence_to_tensor(w2i, sentence):\n",
    "    \"\"\"\n",
    "    Returns the tensor of a sentence.\n",
    "    \"\"\"\n",
    "    \n",
    "    indices = sentence_to_indices(w2i, sentence)\n",
    "    indices.append(EOS_token)\n",
    "    return torch.tensor(indices, dtype=torch.long).view(-1, 1)\n",
    "\n",
    "train_english = read_data(\"data/train_preprocessed.en\")\n",
    "train_french = read_data(\"data/train_preprocessed.fr\")\n",
    "\n",
    "w2i_french = word_to_index(\"data/train_preprocessed.fr.json\")\n",
    "w2i_english = word_to_index(\"data/train_preprocessed.en.json\")\n",
    "\n",
    "i2w_french = index_to_word(w2i_french)\n",
    "i2w_english = index_to_word(w2i_english)\n",
    "\n",
    "EOS_token = w2i_english[\"eos\"]\n",
    "SOS_token = w2i_english[\"sos\"]\n",
    "teacher_forcing_ratio = 0.5\n",
    "encoder = EncoderRNN(len(i2w_english), 256)\n",
    "decoder = AttnDecoderRNN(256, len(i2w_french))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0m 9s (- 46m 36s) (100 0%) 4.0013\n",
      "0m 19s (- 47m 3s) (200 0%) 4.0461\n",
      "0m 28s (- 45m 54s) (300 1%) 4.0258\n",
      "0m 38s (- 45m 18s) (400 1%) 3.8602\n",
      "0m 48s (- 45m 37s) (500 1%) 4.2006\n",
      "0m 57s (- 45m 28s) (600 2%) 3.9255\n",
      "1m 7s (- 45m 35s) (700 2%) 3.9667\n",
      "1m 17s (- 45m 29s) (800 2%) 3.8481\n",
      "1m 28s (- 45m 47s) (900 3%) 3.8421\n",
      "1m 41s (- 47m 10s) (1000 3%) 3.7804\n",
      "1m 50s (- 46m 48s) (1100 3%) 3.6539\n",
      "2m 2s (- 47m 10s) (1200 4%) 3.9055\n",
      "2m 12s (- 47m 0s) (1300 4%) 3.6942\n",
      "2m 23s (- 47m 12s) (1400 4%) 3.7904\n",
      "2m 33s (- 46m 59s) (1500 5%) 3.8079\n",
      "2m 43s (- 46m 37s) (1600 5%) 3.5527\n",
      "2m 55s (- 46m 50s) (1700 5%) 3.5719\n",
      "3m 6s (- 46m 56s) (1800 6%) 3.6230\n",
      "3m 16s (- 46m 45s) (1900 6%) 3.6656\n",
      "3m 26s (- 46m 31s) (2000 6%) 3.6212\n",
      "3m 36s (- 46m 14s) (2100 7%) 3.5914\n",
      "3m 47s (- 46m 6s) (2200 7%) 3.6264\n",
      "3m 56s (- 45m 45s) (2300 7%) 3.5148\n",
      "4m 7s (- 45m 42s) (2400 8%) 3.6877\n",
      "4m 17s (- 45m 24s) (2500 8%) 3.6142\n",
      "4m 27s (- 45m 14s) (2600 8%) 3.4633\n",
      "4m 37s (- 45m 4s) (2700 9%) 3.5433\n",
      "4m 48s (- 45m 1s) (2800 9%) 3.5948\n",
      "4m 57s (- 44m 41s) (2900 10%) 3.5933\n",
      "5m 6s (- 44m 13s) (3000 10%) 3.4577\n",
      "5m 13s (- 43m 41s) (3100 10%) 3.3592\n",
      "5m 21s (- 43m 10s) (3200 11%) 3.3678\n",
      "5m 29s (- 42m 44s) (3300 11%) 3.4950\n",
      "5m 39s (- 42m 34s) (3400 11%) 3.3738\n",
      "5m 49s (- 42m 26s) (3500 12%) 3.5113\n",
      "5m 59s (- 42m 16s) (3600 12%) 3.3225\n",
      "6m 10s (- 42m 12s) (3700 12%) 3.3433\n",
      "6m 20s (- 42m 1s) (3800 13%) 3.4499\n",
      "6m 29s (- 41m 49s) (3900 13%) 3.3959\n",
      "6m 39s (- 41m 37s) (4000 13%) 3.4520\n",
      "6m 48s (- 41m 20s) (4100 14%) 3.3094\n",
      "6m 58s (- 41m 9s) (4200 14%) 3.4106\n",
      "7m 7s (- 40m 53s) (4300 14%) 3.2777\n",
      "7m 15s (- 40m 37s) (4400 15%) 3.3022\n",
      "7m 25s (- 40m 24s) (4500 15%) 3.2486\n",
      "7m 35s (- 40m 15s) (4600 15%) 3.2191\n",
      "7m 43s (- 39m 57s) (4700 16%) 3.3662\n",
      "7m 53s (- 39m 48s) (4800 16%) 3.3215\n",
      "8m 4s (- 39m 41s) (4900 16%) 3.3092\n",
      "8m 14s (- 39m 33s) (5000 17%) 3.3234\n",
      "8m 24s (- 39m 22s) (5100 17%) 3.2030\n",
      "8m 33s (- 39m 10s) (5200 17%) 3.3438\n",
      "8m 43s (- 38m 59s) (5300 18%) 3.2282\n",
      "8m 53s (- 38m 50s) (5400 18%) 3.2793\n",
      "9m 3s (- 38m 40s) (5500 18%) 3.2690\n",
      "9m 12s (- 38m 27s) (5600 19%) 3.1304\n",
      "9m 21s (- 38m 15s) (5700 19%) 3.2582\n",
      "9m 31s (- 38m 5s) (5800 20%) 3.2956\n",
      "9m 40s (- 37m 54s) (5900 20%) 3.2756\n",
      "9m 49s (- 37m 41s) (6000 20%) 3.2763\n",
      "9m 59s (- 37m 29s) (6100 21%) 3.2651\n",
      "10m 7s (- 37m 15s) (6200 21%) 3.3246\n",
      "10m 17s (- 37m 3s) (6300 21%) 2.9257\n",
      "10m 25s (- 36m 50s) (6400 22%) 3.1405\n",
      "10m 35s (- 36m 38s) (6500 22%) 3.2163\n",
      "10m 45s (- 36m 29s) (6600 22%) 3.1251\n",
      "10m 54s (- 36m 19s) (6700 23%) 3.3483\n",
      "11m 3s (- 36m 4s) (6800 23%) 3.2824\n",
      "11m 11s (- 35m 51s) (6900 23%) 3.2283\n",
      "11m 21s (- 35m 42s) (7000 24%) 3.1622\n",
      "11m 31s (- 35m 33s) (7100 24%) 3.2456\n",
      "11m 40s (- 35m 22s) (7200 24%) 3.2294\n",
      "11m 51s (- 35m 14s) (7300 25%) 3.2190\n",
      "12m 2s (- 35m 7s) (7400 25%) 3.1245\n",
      "12m 11s (- 34m 56s) (7500 25%) 2.9618\n",
      "12m 20s (- 34m 45s) (7600 26%) 3.1801\n",
      "12m 29s (- 34m 34s) (7700 26%) 3.1510\n",
      "12m 39s (- 34m 23s) (7800 26%) 3.3555\n",
      "12m 48s (- 34m 13s) (7900 27%) 3.0279\n",
      "12m 58s (- 34m 2s) (8000 27%) 3.0363\n",
      "13m 7s (- 33m 52s) (8100 27%) 3.1967\n",
      "13m 18s (- 33m 46s) (8200 28%) 3.2461\n",
      "13m 29s (- 33m 37s) (8300 28%) 3.1684\n",
      "13m 38s (- 33m 27s) (8400 28%) 3.1204\n",
      "13m 48s (- 33m 18s) (8500 29%) 3.1116\n",
      "13m 58s (- 33m 9s) (8600 29%) 3.2034\n",
      "14m 7s (- 32m 58s) (8700 30%) 3.1259\n",
      "14m 16s (- 32m 47s) (8800 30%) 3.2178\n",
      "14m 26s (- 32m 37s) (8900 30%) 3.1613\n",
      "14m 34s (- 32m 24s) (9000 31%) 3.2795\n",
      "14m 45s (- 32m 16s) (9100 31%) 3.2596\n",
      "14m 55s (- 32m 7s) (9200 31%) 3.2190\n",
      "15m 5s (- 31m 57s) (9300 32%) 3.0250\n",
      "15m 15s (- 31m 49s) (9400 32%) 3.3193\n",
      "15m 25s (- 31m 40s) (9500 32%) 3.2294\n",
      "15m 35s (- 31m 31s) (9600 33%) 3.3249\n",
      "15m 45s (- 31m 21s) (9700 33%) 3.0606\n",
      "15m 54s (- 31m 9s) (9800 33%) 3.0687\n",
      "16m 3s (- 30m 59s) (9900 34%) 3.1436\n",
      "16m 14s (- 30m 51s) (10000 34%) 3.0818\n",
      "16m 24s (- 30m 42s) (10100 34%) 2.9907\n",
      "16m 34s (- 30m 33s) (10200 35%) 3.2269\n",
      "16m 43s (- 30m 22s) (10300 35%) 3.2030\n",
      "16m 53s (- 30m 12s) (10400 35%) 3.0757\n",
      "17m 1s (- 30m 0s) (10500 36%) 2.9788\n",
      "17m 10s (- 29m 48s) (10600 36%) 2.9649\n",
      "17m 19s (- 29m 38s) (10700 36%) 3.0775\n",
      "17m 29s (- 29m 28s) (10800 37%) 3.1940\n",
      "17m 37s (- 29m 16s) (10900 37%) 3.0780\n",
      "17m 46s (- 29m 4s) (11000 37%) 3.0085\n",
      "17m 54s (- 28m 53s) (11100 38%) 3.1885\n",
      "18m 2s (- 28m 41s) (11200 38%) 3.0973\n",
      "18m 11s (- 28m 29s) (11300 38%) 3.0206\n",
      "18m 20s (- 28m 19s) (11400 39%) 3.1363\n",
      "18m 29s (- 28m 7s) (11500 39%) 2.8988\n",
      "18m 38s (- 27m 57s) (11600 40%) 3.1708\n",
      "18m 47s (- 27m 46s) (11700 40%) 3.0652\n",
      "18m 55s (- 27m 35s) (11800 40%) 3.2368\n",
      "19m 5s (- 27m 25s) (11900 41%) 3.2120\n",
      "19m 13s (- 27m 14s) (12000 41%) 2.9151\n",
      "19m 22s (- 27m 3s) (12100 41%) 3.2181\n",
      "19m 31s (- 26m 52s) (12200 42%) 3.1599\n",
      "19m 40s (- 26m 42s) (12300 42%) 3.1452\n",
      "19m 49s (- 26m 32s) (12400 42%) 3.0419\n",
      "19m 59s (- 26m 23s) (12500 43%) 3.1055\n",
      "20m 7s (- 26m 11s) (12600 43%) 2.8824\n",
      "20m 14s (- 25m 59s) (12700 43%) 3.1435\n",
      "20m 22s (- 25m 47s) (12800 44%) 3.0781\n",
      "20m 30s (- 25m 35s) (12900 44%) 3.0435\n",
      "20m 37s (- 25m 23s) (13000 44%) 3.0210\n",
      "20m 46s (- 25m 12s) (13100 45%) 2.9654\n",
      "20m 55s (- 25m 3s) (13200 45%) 3.0893\n",
      "21m 5s (- 24m 53s) (13300 45%) 3.0263\n",
      "21m 14s (- 24m 43s) (13400 46%) 3.1450\n",
      "21m 24s (- 24m 34s) (13500 46%) 3.2451\n",
      "21m 33s (- 24m 24s) (13600 46%) 3.1219\n",
      "21m 42s (- 24m 14s) (13700 47%) 2.9687\n",
      "21m 51s (- 24m 4s) (13800 47%) 2.9621\n",
      "22m 1s (- 23m 55s) (13900 47%) 2.9908\n",
      "22m 10s (- 23m 45s) (14000 48%) 3.0420\n",
      "22m 20s (- 23m 36s) (14100 48%) 3.0443\n",
      "22m 29s (- 23m 26s) (14200 48%) 2.9313\n",
      "22m 38s (- 23m 16s) (14300 49%) 2.9129\n",
      "22m 46s (- 23m 5s) (14400 49%) 3.0830\n",
      "22m 56s (- 22m 56s) (14500 50%) 3.2103\n",
      "23m 5s (- 22m 46s) (14600 50%) 3.0319\n",
      "23m 15s (- 22m 37s) (14700 50%) 3.0492\n",
      "23m 25s (- 22m 28s) (14800 51%) 3.0710\n",
      "23m 33s (- 22m 17s) (14900 51%) 3.2074\n",
      "23m 43s (- 22m 8s) (15000 51%) 2.9074\n",
      "23m 52s (- 21m 59s) (15100 52%) 3.2094\n",
      "24m 3s (- 21m 50s) (15200 52%) 3.0580\n",
      "24m 14s (- 21m 42s) (15300 52%) 3.0754\n",
      "24m 25s (- 21m 34s) (15400 53%) 3.0973\n",
      "24m 35s (- 21m 25s) (15500 53%) 3.3535\n",
      "24m 45s (- 21m 15s) (15600 53%) 3.1192\n",
      "24m 55s (- 21m 7s) (15700 54%) 2.9928\n",
      "25m 6s (- 20m 58s) (15800 54%) 3.1866\n",
      "25m 16s (- 20m 49s) (15900 54%) 3.1972\n",
      "25m 26s (- 20m 40s) (16000 55%) 3.1439\n",
      "25m 36s (- 20m 30s) (16100 55%) 3.1171\n",
      "25m 48s (- 20m 23s) (16200 55%) 3.2144\n",
      "26m 2s (- 20m 17s) (16300 56%) 3.1728\n",
      "26m 12s (- 20m 8s) (16400 56%) 3.0573\n",
      "26m 22s (- 19m 58s) (16500 56%) 2.9780\n",
      "26m 33s (- 19m 50s) (16600 57%) 3.1754\n",
      "26m 42s (- 19m 40s) (16700 57%) 3.2390\n",
      "26m 55s (- 19m 33s) (16800 57%) 3.0759\n",
      "27m 5s (- 19m 23s) (16900 58%) 3.0074\n",
      "27m 13s (- 19m 13s) (17000 58%) 2.9860\n",
      "27m 22s (- 19m 3s) (17100 58%) 3.0750\n",
      "27m 31s (- 18m 52s) (17200 59%) 3.1353\n",
      "27m 41s (- 18m 43s) (17300 59%) 3.1015\n",
      "27m 51s (- 18m 34s) (17400 60%) 3.1887\n",
      "28m 1s (- 18m 24s) (17500 60%) 3.2213\n",
      "28m 11s (- 18m 15s) (17600 60%) 3.0171\n",
      "28m 21s (- 18m 6s) (17700 61%) 3.1606\n",
      "28m 31s (- 17m 56s) (17800 61%) 3.0039\n",
      "28m 41s (- 17m 47s) (17900 61%) 3.2078\n",
      "28m 50s (- 17m 37s) (18000 62%) 2.9261\n",
      "29m 0s (- 17m 27s) (18100 62%) 3.1065\n",
      "29m 9s (- 17m 18s) (18200 62%) 2.9352\n",
      "29m 19s (- 17m 8s) (18300 63%) 3.1661\n",
      "29m 28s (- 16m 59s) (18400 63%) 3.0947\n",
      "29m 38s (- 16m 49s) (18500 63%) 3.3217\n",
      "29m 48s (- 16m 40s) (18600 64%) 2.9371\n",
      "29m 58s (- 16m 30s) (18700 64%) 3.2013\n",
      "30m 8s (- 16m 21s) (18800 64%) 2.9702\n",
      "30m 19s (- 16m 12s) (18900 65%) 3.2577\n",
      "30m 28s (- 16m 2s) (19000 65%) 2.9508\n",
      "30m 37s (- 15m 52s) (19100 65%) 2.9147\n",
      "30m 46s (- 15m 42s) (19200 66%) 3.0677\n",
      "30m 59s (- 15m 34s) (19300 66%) 3.1467\n",
      "31m 9s (- 15m 25s) (19400 66%) 3.0811\n",
      "31m 20s (- 15m 15s) (19500 67%) 3.0562\n",
      "31m 29s (- 15m 6s) (19600 67%) 3.3498\n",
      "31m 40s (- 14m 57s) (19700 67%) 3.1576\n",
      "31m 50s (- 14m 47s) (19800 68%) 3.1353\n",
      "32m 1s (- 14m 38s) (19900 68%) 3.0385\n",
      "32m 11s (- 14m 29s) (20000 68%) 3.0155\n",
      "32m 23s (- 14m 20s) (20100 69%) 3.2147\n",
      "32m 33s (- 14m 11s) (20200 69%) 2.9157\n",
      "32m 43s (- 14m 1s) (20300 70%) 3.1030\n",
      "32m 53s (- 13m 52s) (20400 70%) 3.0356\n",
      "33m 3s (- 13m 42s) (20500 70%) 2.9699\n",
      "33m 14s (- 13m 33s) (20600 71%) 3.0286\n",
      "33m 24s (- 13m 23s) (20700 71%) 3.2004\n",
      "33m 35s (- 13m 14s) (20800 71%) 3.1012\n",
      "33m 45s (- 13m 5s) (20900 72%) 3.0209\n",
      "33m 56s (- 12m 55s) (21000 72%) 3.0995\n",
      "34m 7s (- 12m 46s) (21100 72%) 3.0220\n",
      "34m 17s (- 12m 36s) (21200 73%) 2.9695\n",
      "34m 26s (- 12m 27s) (21300 73%) 2.8785\n",
      "34m 38s (- 12m 18s) (21400 73%) 3.0153\n",
      "34m 47s (- 12m 8s) (21500 74%) 2.9416\n",
      "34m 57s (- 11m 58s) (21600 74%) 2.9753\n",
      "35m 7s (- 11m 49s) (21700 74%) 2.8756\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35m 16s (- 11m 39s) (21800 75%) 3.0539\n",
      "35m 25s (- 11m 29s) (21900 75%) 2.8515\n",
      "35m 34s (- 11m 19s) (22000 75%) 3.0535\n",
      "35m 45s (- 11m 9s) (22100 76%) 2.9054\n",
      "35m 55s (- 11m 0s) (22200 76%) 2.9969\n",
      "36m 5s (- 10m 50s) (22300 76%) 3.0142\n",
      "36m 17s (- 10m 41s) (22400 77%) 3.1089\n"
     ]
    }
   ],
   "source": [
    "def showPlot(points):\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    # this locator puts ticks at regular intervals\n",
    "    loc = ticker.MultipleLocator(base=0.2)\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    plt.plot(points)\n",
    "\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))    \n",
    "    \n",
    "\n",
    "def train(input_sentence, target_sentence, w2i_english, \n",
    "          w2i_french, encoder, decoder, encoder_optimizer, \n",
    "          decoder_optimizer, criterion, minibatch_size, \n",
    "          max_length=MAX_LENGTH):\n",
    "    \"\"\"\n",
    "    Does one iteration of training.\n",
    "    \"\"\"\n",
    "    \n",
    "    loss = 0     \n",
    "    input_tensor = sentence_to_tensor(w2i_english, input_sentence)\n",
    "    target_tensor = sentence_to_tensor(w2i_french, target_sentence)\n",
    "\n",
    "    encoder_hidden = encoder.initHidden()\n",
    "\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "\n",
    "    input_length = input_tensor.size(0)\n",
    "    target_length = target_tensor.size(0)\n",
    "\n",
    "    encoder_outputs = torch.zeros(max_length, encoder.hidden_size)\n",
    "\n",
    "    if input_length > MAX_LENGTH: input_length = MAX_LENGTH\n",
    "    \n",
    "    for ei in range(input_length):\n",
    "        encoder_output, encoder_hidden = encoder(input_tensor[ei], encoder_hidden)\n",
    "        encoder_outputs[ei] = encoder_output[0, 0]\n",
    "\n",
    "    decoder_input = torch.tensor([[SOS_token]])\n",
    "    decoder_hidden = encoder_hidden\n",
    "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "\n",
    "    if use_teacher_forcing:\n",
    "        # Teacher forcing: Feed the target as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            loss += criterion(decoder_output, target_tensor[di])\n",
    "            decoder_input = target_tensor[di]  # Teacher forcing\n",
    "    else:\n",
    "        # Without teacher forcing: use its own predictions as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            topv, topi = decoder_output.topk(1)\n",
    "            decoder_input = topi.squeeze().detach()  # detach from history as input\n",
    "\n",
    "            loss += criterion(decoder_output, target_tensor[di])\n",
    "            if decoder_input.item() == EOS_token:\n",
    "                break         \n",
    "    loss.backward()\n",
    "\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "    return loss.item()/target_length\n",
    "\n",
    "\n",
    "def train_iterations(w2i_english, w2i_french, train_english, train_french,\n",
    "                     encoder, decoder, minibatch_size, n_iters, print_every=100, \n",
    "                     plot_every=100, learning_rate=0.01):\n",
    "    \"\"\"\n",
    "    Trains the Encoder-Decoder model for a certain amount of iterations.\n",
    "    \"\"\"\n",
    "    \n",
    "    start = time.time()\n",
    "    plot_losses = []\n",
    "    print_loss_total = 0  # Reset every print_every\n",
    "    plot_loss_total = 0  # Reset every plot_every\n",
    "\n",
    "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
    "    criterion = nn.NLLLoss()\n",
    "\n",
    "    for iter in range(1, n_iters + 1):\n",
    "        input_sentence = train_english[iter-1]\n",
    "        target_sentence = train_french[iter-1]\n",
    "        loss = train(input_sentence, target_sentence, w2i_english, w2i_french,\n",
    "                     encoder, decoder, encoder_optimizer, decoder_optimizer, \n",
    "                     criterion, minibatch_size)        \n",
    "        print_loss_total += loss\n",
    "        plot_loss_total += loss\n",
    "\n",
    "        if iter % print_every == 0:\n",
    "            print_loss_avg = print_loss_total / print_every\n",
    "            print_loss_total = 0\n",
    "            print('%s (%d %d%%) %.4f' % (timeSince(start, iter/n_iters),\n",
    "                                         iter, float(iter)/n_iters*100, print_loss_avg))\n",
    "\n",
    "        if iter % plot_every == 0:\n",
    "            plot_loss_avg = plot_loss_total / plot_every\n",
    "            plot_losses.append(plot_loss_avg)\n",
    "            plot_loss_total = 0\n",
    "    showPlot(plot_losses)\n",
    "    \n",
    "    \n",
    "trainloader_english = torch.utils.data.DataLoader(train_english, \n",
    "                                                  batch_size=32, shuffle=False, \n",
    "                                                  num_workers=8)\n",
    "trainloader_french = torch.utils.data.DataLoader(train_french,\n",
    "                                                batch_size=32, shuffle=False,\n",
    "                                                num_workers=8)\n",
    "# testloader = torch.utils.data.DataLoader(testset, batch_size=32, shuffle=False, num_workers=8)\n",
    "    \n",
    "train_iterations(w2i_english, w2i_french, train_english, train_french,\n",
    "                 encoder, decoder, 10, 29000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
