{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "PyTorch shizz.\n",
    "\"\"\"\n",
    "\n",
    "# from __future__ import unicode_literals, print_function, division\n",
    "# from io import open\n",
    "# import unicodedata\n",
    "# import string\n",
    "# import re\n",
    "# import random\n",
    "\n",
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# from torch import optim\n",
    "# import torch.nn.functional as F\n",
    "\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# class Lang:\n",
    "#     def __init__(self, name):\n",
    "#         self.name = name\n",
    "#         self.word2index = {}\n",
    "#         self.word2count = {}\n",
    "#         self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
    "#         self.n_words = 2  # Count SOS and EOS\n",
    "\n",
    "#     def addSentence(self, sentence):\n",
    "#         for word in sentence.split(' '):\n",
    "#             self.addWord(word)\n",
    "\n",
    "#     def addWord(self, word):\n",
    "#         if word not in self.word2index:\n",
    "#             self.word2index[word] = self.n_words\n",
    "#             self.word2count[word] = 1\n",
    "#             self.index2word[self.n_words] = word\n",
    "#             self.n_words += 1\n",
    "#         else:\n",
    "#             self.word2count[word] += 1\n",
    "            \n",
    "            \n",
    "# def readLangs(lang1, lang2, reverse=False):\n",
    "#     print(\"Reading lines...\")\n",
    "\n",
    "#     # Read the file and split into lines\n",
    "#     lines = open('data/%s-%s.txt' % (lang1, lang2), encoding='utf-8').\\\n",
    "#         read().strip().split('\\n')\n",
    "\n",
    "#     # Split every line into pairs and normalize\n",
    "#     pairs = [[normalizeString(s) for s in l.split('\\t')] for l in lines]\n",
    "\n",
    "#     # Reverse pairs, make Lang instances\n",
    "#     if reverse:\n",
    "#         pairs = [list(reversed(p)) for p in pairs]\n",
    "#         input_lang = Lang(lang2)\n",
    "#         output_lang = Lang(lang1)\n",
    "#     else:\n",
    "#         input_lang = Lang(lang1)\n",
    "#         output_lang = Lang(lang2)\n",
    "\n",
    "#     return input_lang, output_lang, pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29000\n",
      "29000\n"
     ]
    }
   ],
   "source": [
    "def read_data(file_name):\n",
    "    \"\"\"\n",
    "    Reads the data and returns it in a list.\n",
    "    \"\"\"\n",
    "    \n",
    "    f = open(file_name, \"r\")\n",
    "    return [line.strip().split() for line in f.readlines()]\n",
    "\n",
    "\n",
    "def get_dictionary(file_name):\n",
    "    \"\"\"\n",
    "    Obtains the vocabulary of a file and returns it \n",
    "    in a dictionary to be able to use w2i.\n",
    "    \"\"\"\n",
    "    \n",
    "    file = open(file_name) \n",
    "    return json.load(file)\n",
    "\n",
    "\n",
    "def reverse_dictionary(dictionary):\n",
    "    \"\"\"\n",
    "    Reverses the dictionary such that i2w can be used.\n",
    "    \"\"\"\n",
    "    \n",
    "    reversed_dict = {}\n",
    "    \n",
    "    for word, index in dictionary.items():\n",
    "        reversed_dict[index] = word\n",
    "    return reversed_dict\n",
    "\n",
    "\n",
    "def initialize_embedding(dictionary, dimension):\n",
    "    \"\"\"\n",
    "    Initialize embeddings randomly using a uniform\n",
    "    distribution. The embeddings are standardized\n",
    "    such that the mean is zero and the standard deviation is 0.01.\n",
    "    \"\"\"\n",
    "    \n",
    "    print(len(dictionary))\n",
    "    \n",
    "    embedding = np.random.uniform(-0.1, 0.1, (len(dictionary), dimension))\n",
    "    embedding = embedding - np.mean(embedding, axis=0)\n",
    "    embedding = embedding/np.std(embedding)\n",
    "    return embedding\n",
    "\n",
    "\n",
    "def embed_sentence(sentence, embeddings, dictionary):\n",
    "    \"\"\"\n",
    "    Returns the embedding of a sentence.\n",
    "    \"\"\"\n",
    "    \n",
    "    embedding = []\n",
    "    \n",
    "    for word in sentence:\n",
    "        index = dictionary[word]\n",
    "        embedding.append(embeddings[index, :])\n",
    "    return embedding\n",
    "\n",
    "train_english = read_data(\"data/train_preprocessed.en\")\n",
    "train_french = read_data(\"data/train_preprocessed.fr\")\n",
    "# get_pairs(train_english, train_french)\n",
    "\n",
    "\n",
    "# w2i_french = get_dictionary(\"data/train_preprocessed.fr.json\")\n",
    "# w2i_english = get_dictionary(\"data/train_preprocessed.en.json\")\n",
    "# i2w_french = reverse_dictionary(w2i_french)\n",
    "# i2w_english = reverse_dictionary(w2i_english)\n",
    "\n",
    "# embeddings = initialize_embedding(french_dict, 50)\n",
    "# embed_sentence(train_english[0], embeddings, english_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
