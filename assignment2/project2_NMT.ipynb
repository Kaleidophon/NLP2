{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import math\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "import os\n",
    "import progressbar\n",
    "import random\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LENGTH = 50\n",
    "\n",
    "class EncoderRNN(nn.Module): \n",
    "    def __init__(self, input_size, hidden_size, positional, dropout_p=0.1):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.dropout_p = dropout_p\n",
    "\n",
    "        self.positional = positional\n",
    "        self.word_embedding = nn.Embedding(input_size, hidden_size)\n",
    "        # input_size moet MAX_LENGTH worden\n",
    "        self.pos_embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.dropout = nn.Dropout(self.dropout_p)\n",
    "        self.linear = nn.Linear(hidden_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        word_embedded = self.word_embedding(input).view(1, 1, -1)\n",
    "        \n",
    "        if self.positional:\n",
    "            pos_embedded = self.pos_embedding(input).view(1, 1, -1)\n",
    "            output = self.dropout(word_embedded + pos_embedded)\n",
    "            output = self.linear(output)\n",
    "            hidden = self.linear(hidden)\n",
    "        else:\n",
    "            output, hidden = self.gru(word_embedded, hidden)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size)\n",
    "    \n",
    "    \n",
    "class AttnDecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=MAX_LENGTH):\n",
    "        super(AttnDecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.dropout_p = dropout_p\n",
    "        self.max_length = max_length\n",
    "\n",
    "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
    "        self.attn = nn.Linear(self.hidden_size * 2, self.max_length)\n",
    "        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
    "        self.dropout = nn.Dropout(self.dropout_p)\n",
    "        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n",
    "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
    "\n",
    "    def forward(self, input, hidden, encoder_outputs):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        embedded = self.dropout(embedded)\n",
    "\n",
    "        attn_weights = F.softmax(\n",
    "            self.attn(torch.cat((embedded[0], hidden[0]), 1)), dim=1)\n",
    "        attn_applied = torch.bmm(attn_weights.unsqueeze(0),\n",
    "                                 encoder_outputs.unsqueeze(0))\n",
    "\n",
    "        output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
    "        output = self.attn_combine(output).unsqueeze(0)\n",
    "\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "\n",
    "        output = F.log_softmax(self.out(output[0]), dim=1)\n",
    "        return output, hidden, attn_weights\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size)\n",
    "    \n",
    "class NMT(nn.Module):\n",
    "    def __init__(self, i2w_english, i2w_french, hidden_size, positional, criterion):\n",
    "        super(NMT, self).__init__()\n",
    "        self.encoder = EncoderRNN(len(i2w_english), hidden_size, positional)\n",
    "        self.decoder = AttnDecoderRNN(hidden_size, len(i2w_french))\n",
    "        self.criterion = criterion\n",
    "    \n",
    "    def forward(self, input_tensor, target_tensor):\n",
    "        \n",
    "        loss = 0\n",
    "        \n",
    "        input_length = input_tensor.size(0)\n",
    "        target_length = target_tensor.size(0)\n",
    "        \n",
    "        encoder_hidden = self.encoder.initHidden()\n",
    "        encoder_outputs = torch.zeros(MAX_LENGTH, self.encoder.hidden_size)\n",
    "        \n",
    "        if input_length > MAX_LENGTH: input_length = MAX_LENGTH\n",
    "    \n",
    "        for ei in range(input_length):\n",
    "            encoder_output, encoder_hidden = self.encoder(input_tensor[ei], encoder_hidden)\n",
    "            encoder_outputs[ei] = encoder_output[0, 0]\n",
    "            \n",
    "        decoder_input = torch.tensor([[SOS_token_fr]])\n",
    "        decoder_hidden = encoder_hidden\n",
    "\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = self.decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            \n",
    "            topv, topi = decoder_output.topk(1)\n",
    "            decoder_input = topi.squeeze().detach()  # detach from history as input\n",
    "\n",
    "            loss += self.criterion(decoder_output, target_tensor[di])\n",
    "            if decoder_input.item() == EOS_token_fr:\n",
    "                return loss\n",
    "            \n",
    "        return loss\n",
    "    \n",
    "    def evaluate(self, w2i_english, i2w_french, sentence):\n",
    "    \n",
    "        with torch.no_grad():\n",
    "            input_tensor = sentence_to_tensor(w2i_english, sentence)\n",
    "            input_length = input_tensor.size()[0]\n",
    "            encoder_hidden = self.encoder.initHidden()\n",
    "\n",
    "            encoder_outputs = torch.zeros(MAX_LENGTH, self.encoder.hidden_size)\n",
    "\n",
    "            if input_length > MAX_LENGTH: input_length = MAX_LENGTH\n",
    "\n",
    "            for ei in range(input_length):\n",
    "                encoder_output, encoder_hidden = self.encoder(input_tensor[ei],\n",
    "                                                         encoder_hidden)\n",
    "                encoder_outputs[ei] += encoder_output[0, 0]\n",
    "\n",
    "            decoder_input = torch.tensor([[SOS_token_fr]])  # SOS\n",
    "\n",
    "            decoder_hidden = encoder_hidden\n",
    "\n",
    "            decoded_words = []\n",
    "            decoder_attentions = torch.zeros(MAX_LENGTH, MAX_LENGTH)\n",
    "\n",
    "            for di in range(MAX_LENGTH):\n",
    "                decoder_output, decoder_hidden, decoder_attention = self.decoder(\n",
    "                    decoder_input, decoder_hidden, encoder_outputs)\n",
    "                decoder_attentions[di] = decoder_attention.data\n",
    "                topv, topi = decoder_output.data.topk(1)\n",
    "                if topi.item() == EOS_token_fr:\n",
    "                    decoded_words.append(\"<eos>\")\n",
    "                    break\n",
    "                else:\n",
    "                    decoded_words.append(i2w_french[topi.item()])\n",
    "\n",
    "                decoder_input = topi.squeeze().detach()\n",
    "\n",
    "        return decoded_words, decoder_attentions[:di + 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(file_name):\n",
    "    \"\"\"\n",
    "    Reads the data and returns it in a list.\n",
    "    \"\"\"\n",
    "    \n",
    "    f = open(file_name, \"r\")\n",
    "    return [line.strip().split() for line in f.readlines()]\n",
    "\n",
    "\n",
    "def word_to_index(file_name):\n",
    "    \"\"\"\n",
    "    Obtains the vocabulary of a file and returns it \n",
    "    in a dictionary to be able to use w2i.\n",
    "    \"\"\"\n",
    "    \n",
    "    file = open(file_name) \n",
    "    w2i = json.load(file)\n",
    "    w2i[\"<sos>\"] = len(w2i)\n",
    "    return w2i\n",
    "\n",
    "\n",
    "def index_to_word(dictionary):\n",
    "    \"\"\"\n",
    "    Reverses the dictionary such that i2w can be used.\n",
    "    \"\"\"\n",
    "    \n",
    "    reversed_dict = {}\n",
    "    \n",
    "    for word, index in dictionary.items():\n",
    "        reversed_dict[index] = word\n",
    "    reversed_dict[index + 1] = \"<sos>\" \n",
    "    return reversed_dict\n",
    "\n",
    "\n",
    "def sentence_to_indices(w2i, sentence):\n",
    "    \"\"\"\n",
    "    Returns the indices of the words in a sentence in a list.\n",
    "    \"\"\"\n",
    "    \n",
    "    return [w2i[word] for word in sentence]\n",
    "\n",
    "\n",
    "def sentence_to_tensor(w2i, sentence):\n",
    "    \"\"\"\n",
    "    Returns the tensor of a sentence.\n",
    "    \"\"\"\n",
    "    \n",
    "    indices = sentence_to_indices(w2i, sentence)\n",
    "    indices.append(w2i[\"<eos>\"])\n",
    "    return torch.tensor(indices, dtype=torch.long).view(-1, 1)\n",
    "\n",
    "train_english = read_data(\"data/train_preprocessed.en\")\n",
    "train_french = read_data(\"data/train_preprocessed.fr\")\n",
    "\n",
    "val_english = read_data(\"data/val_preprocessed.en\")\n",
    "val_french = read_data(\"data/val_preprocessed.fr\")\n",
    "\n",
    "w2i_french = word_to_index(\"data/train_preprocessed.fr.json\")\n",
    "w2i_english = word_to_index(\"data/train_preprocessed.en.json\")\n",
    "\n",
    "i2w_french = index_to_word(w2i_french)\n",
    "i2w_english = index_to_word(w2i_english)\n",
    "\n",
    "EOS_token_en = w2i_english[\"<eos>\"]\n",
    "SOS_token_en = w2i_english[\"<sos>\"]\n",
    "\n",
    "EOS_token_fr = w2i_french[\"<eos>\"]\n",
    "SOS_token_fr = w2i_french[\"<sos>\"]\n",
    "\n",
    "teacher_forcing_ratio = 0.5\n",
    "positional = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "N/A% (0 of 1000) |                       | Elapsed Time: 0:00:00 ETA:  --:--:--"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1 of 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (1000 of 1000) |####################| Elapsed Time: 0:01:38 Time:  0:01:38\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 3372.313117611023\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x108835da0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def showPlot(points):\n",
    "    plt.figure()\n",
    "#     fig, ax = plt.subplots()\n",
    "    # this locator puts ticks at regular intervals\n",
    "#     loc = ticker.MultipleLocator(base=0.2)\n",
    "#     ax.yaxis.set_major_locator(loc)\n",
    "    plt.plot(points)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))    \n",
    "\n",
    "\n",
    "def train(input_sentence, target_sentence, w2i_english, \n",
    "          w2i_french, nmt, nmt_optimizer, criterion, max_length=MAX_LENGTH):\n",
    "    \"\"\"\n",
    "    Does one iteration of training.\n",
    "    \"\"\"\n",
    "    \n",
    "    loss = 0     \n",
    "    output_sentence = []\n",
    "    input_tensor = sentence_to_tensor(w2i_english, input_sentence)\n",
    "    target_tensor = sentence_to_tensor(w2i_french, target_sentence)\n",
    "\n",
    "    # encoder_hidden = encoder.initHidden()\n",
    "\n",
    "    nmt_optimizer.zero_grad()\n",
    "\n",
    "#     input_length = input_tensor.size(0)\n",
    "#     target_length = target_tensor.size(0)\n",
    "\n",
    "#     encoder_outputs = torch.zeros(max_length, encoder.hidden_size)\n",
    "\n",
    "#     if input_length > MAX_LENGTH: input_length = MAX_LENGTH\n",
    "    \n",
    "#     for ei in range(input_length):\n",
    "#         encoder_output, encoder_hidden = encoder(input_tensor[ei], encoder_hidden)\n",
    "#         encoder_outputs[ei] = encoder_output[0, 0]\n",
    "\n",
    "#     decoder_input = torch.tensor([[SOS_token]])\n",
    "#     decoder_hidden = encoder_hidden\n",
    "#     use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "\n",
    "#     if use_teacher_forcing:\n",
    "#         # Teacher forcing: Feed the target as the next input\n",
    "#         for di in range(target_length):\n",
    "#             decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "#                 decoder_input, decoder_hidden, encoder_outputs)\n",
    "            \n",
    "#             loss += criterion(decoder_output, target_tensor[di])\n",
    "#             decoder_input = target_tensor[di]  # Teacher forcing\n",
    "#     else:\n",
    "#         # Without teacher forcing: use its own predictions as the next input\n",
    "#         for di in range(target_length):\n",
    "#             decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "#                 decoder_input, decoder_hidden, encoder_outputs)\n",
    "            \n",
    "#             topv, topi = decoder_output.topk(1)\n",
    "#             decoder_input = topi.squeeze().detach()  # detach from history as input\n",
    "\n",
    "#             loss += criterion(decoder_output, target_tensor[di])\n",
    "#             if decoder_input.item() == EOS_token:\n",
    "#                 break         \n",
    "\n",
    "    loss = nmt.forward(input_tensor, target_tensor)\n",
    "    target_length = target_tensor.size(0)\n",
    "    \n",
    "    loss.backward()\n",
    "    nmt_optimizer.step()\n",
    "    \n",
    "    return loss.item()/target_length\n",
    "\n",
    "\n",
    "def train_dataset(w2i_english, w2i_french, train_english, \n",
    "                  train_french, nmt, learning_rate):\n",
    "    \"\"\"\n",
    "    Trains the Encoder-Decoder model for the entire data set.\n",
    "    \"\"\"\n",
    "    \n",
    "    start = time.time()\n",
    "\n",
    "    nmt_optimizer = optim.SGD(nmt.parameters(), lr=learning_rate)\n",
    "    criterion = nn.NLLLoss()\n",
    "    total_loss = 0\n",
    "\n",
    "#     with progressbar.ProgressBar(max_value=len(train_english)) as bar:\n",
    "    with progressbar.ProgressBar(max_value=1000) as bar:\n",
    "#         for iter in range(1, len(train_english) + 1):\n",
    "        for iter in range(1, 1000+1):\n",
    "            input_sentence = train_english[iter-1]\n",
    "            target_sentence = train_french[iter-1]\n",
    "            loss = train(input_sentence, target_sentence, w2i_english, \n",
    "                         w2i_french, nmt, nmt_optimizer, criterion)\n",
    "            total_loss += loss\n",
    "            bar.update(iter-1)\n",
    "    return total_loss\n",
    "\n",
    "\n",
    "def train_epochs(w2i_english, w2i_french, train_english, train_french,\n",
    "                nmt, num_epochs, learning_rate=0.01):\n",
    "    \"\"\"\n",
    "    Trains the Encoder-Decoder for a certain amount of epochs.\n",
    "    \"\"\"\n",
    "    \n",
    "    losses = []\n",
    "    \n",
    "    for iter in range(1, num_epochs + 1):\n",
    "        print(\"Iteration\", iter, \"of\", num_epochs)\n",
    "        loss = train_dataset(w2i_english, w2i_french,\n",
    "                             train_english, train_french, \n",
    "                             nmt, learning_rate)\n",
    "        print(\"loss:\", loss)\n",
    "        losses.append(loss)\n",
    "    showPlot(losses)\n",
    "    \n",
    "# encoder = EncoderRNN(len(i2w_english), 256, positional)\n",
    "# decoder = AttnDecoderRNN(256, len(i2w_french))\n",
    "criterion = nn.NLLLoss()\n",
    "nmt = NMT(i2w_english, i2w_french, 256, positional, criterion)\n",
    "train_epochs(w2i_english, w2i_french, train_english, train_french,\n",
    "             nmt, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []\n",
    "    \n",
    "for sentence in val_english:\n",
    "    predicted_words, attentions = nmt.evaluate(w2i_english, i2w_french, sentence)\n",
    "    predicted_sentence = ' '.join(predicted_words)\n",
    "    predictions.append(predicted_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_predictions(predictions, file_name):\n",
    "    \"\"\"\n",
    "    Saves the encoded predicted sentences decoded to a file.\n",
    "    \"\"\"\n",
    "    \n",
    "    with open(\"temp_encoded.txt\", \"w\") as f:\n",
    "        for sentence in predictions:\n",
    "            f.write(sentence + \"\\n\")\n",
    "    f.close()\n",
    "    \n",
    "    command = \"sed -r 's/(@@ )|(@@ ?$)//g' temp_encoded.txt > \" + file_name\n",
    "    os.system(command)\n",
    "    os.remove(\"temp_encoded.txt\")\n",
    "\n",
    "save_predictions(predictions, \"test_val.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Old stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def evaluate(encoder, decoder, w2i_english, i2w_french,\n",
    "#              sentence, max_length=MAX_LENGTH):\n",
    "#     \"\"\"\n",
    "#     Evaluates a sentence.\n",
    "#     \"\"\"\n",
    "    \n",
    "#     with torch.no_grad():\n",
    "#         input_tensor = sentence_to_tensor(w2i_english, sentence)\n",
    "#         input_length = input_tensor.size()[0]\n",
    "#         encoder_hidden = encoder.initHidden()\n",
    "\n",
    "#         encoder_outputs = torch.zeros(max_length, encoder.hidden_size)\n",
    "\n",
    "#         if input_length > MAX_LENGTH: input_length = MAX_LENGTH\n",
    "        \n",
    "#         for ei in range(input_length):\n",
    "#             encoder_output, encoder_hidden = encoder(input_tensor[ei],\n",
    "#                                                      encoder_hidden)\n",
    "#             encoder_outputs[ei] += encoder_output[0, 0]\n",
    "\n",
    "#         decoder_input = torch.tensor([[SOS_token]])  # SOS\n",
    "\n",
    "#         decoder_hidden = encoder_hidden\n",
    "\n",
    "#         decoded_words = []\n",
    "#         decoder_attentions = torch.zeros(max_length, max_length)\n",
    "\n",
    "#         for di in range(max_length):\n",
    "#             decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "#                 decoder_input, decoder_hidden, encoder_outputs)\n",
    "#             decoder_attentions[di] = decoder_attention.data\n",
    "#             topv, topi = decoder_output.data.topk(1)\n",
    "#             if topi.item() == EOS_token_fr:\n",
    "#                 decoded_words.append(\"<eos>\")\n",
    "#                 break\n",
    "#             else:\n",
    "#                 decoded_words.append(i2w_french[topi.item()])\n",
    "\n",
    "#             decoder_input = topi.squeeze().detach()\n",
    "\n",
    "#         return decoded_words, decoder_attentions[:di + 1]\n",
    "    \n",
    "    \n",
    "# def evaluate_dataset(encoder, decoder, val_english):\n",
    "#     \"\"\"\n",
    "#     Evaluates the entire validation set.\n",
    "#     \"\"\"\n",
    "    \n",
    "#     predictions = []\n",
    "    \n",
    "#     for sentence in val_english:\n",
    "#         predicted_words, attentions = evaluate(encoder, decoder, w2i_english, i2w_french, sentence)\n",
    "#         predicted_sentence = ' '.join(predicted_words)\n",
    "#         predictions.append(predicted_sentence)\n",
    "#     return predictions\n",
    "        \n",
    "\n",
    "# def save_predictions(predictions, file_name):\n",
    "#     \"\"\"\n",
    "#     Saves the encoded predicted sentences decoded to a file.\n",
    "#     \"\"\"\n",
    "    \n",
    "#     with open(\"temp_encoded.txt\", \"w\") as f:\n",
    "#         for sentence in predictions:\n",
    "#             f.write(sentence + \"\\n\")\n",
    "#     f.close()\n",
    "    \n",
    "#     command = \"sed -r 's/(@@ )|(@@ ?$)//g' temp_encoded.txt > \" + file_name\n",
    "#     os.system(command)\n",
    "#     os.remove(\"temp_encoded.txt\")\n",
    "    \n",
    "\n",
    "# predictions = evaluate_dataset(encoder, decoder, val_english)\n",
    "# save_predictions(predictions, \"test_val.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(train_english))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
